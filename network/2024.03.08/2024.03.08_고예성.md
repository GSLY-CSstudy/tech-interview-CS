- **HTTP/1.1과 HTTP/2의 차이점은 무엇인가요?**
    
    ![Untitled](https://github.com/GSLY-CSstudy/tech-interview-CS/assets/71485411/833c054d-02d9-4ccf-b5bb-918f72a845a2)

    위의 첫번째 그림을 보면 HTTP/1.0에서는 한 번의 요청마다 하나의 응답을 받는 방식이었습니다.
    
    HTTP/1.1에서는 이러한 방식으로부터 구현의 단순성과 접근성에 주안점을 두고 최적화되었습니다. 
    
    초기에 HTTP/1.1은 이를 개선하여 한 번 맺은 커넥션을 지속적으로 연결한 후 요청 하나를 보내고 그에 대한 응답 하나만을 받는 방식이었습니다. 
    
    하지만 이전의 응답을 받아야만 다음 요청을 보낼 수 있기 때문에 회전 지연(latency)을 피할 수 없었습니다.
    
    이를 해결하기 위해 병렬 커넥션이나 파이프라인 커넥션이 도입되었지만 성능 개선에 근본적인 해결책은 되지 못했습니다.(HOL: Head-of-line-blocking 발생)
    
    이때 구글에서 SPDY 프로토콜을 개발하여 이를 해결하고자 했습니다.
    
    SPDY 프로토콜은 헤더를 압축하여 대역폭을 절약하고, 클라이언트가 요청을 보내지 않아도 서버가 능동적으로 리소스를 푸시하는 기능을 갖추고 있습니다.
    
    HTTP/2.0은 SPDY 프로토콜을 기반으로 설계되었습니다.
    
    HTTP/2.0은 서버와 클라이언트 사이의 TCP 커넥션 사이에서 동작합니다.
  
    ![Untitled](https://github.com/GSLY-CSstudy/tech-interview-CS/assets/71485411/ac7abc1a-d678-493a-af0c-d145ebb31dbb)

    HTTP/2.0 요청과 응답은 길이가 정의된 한 개 이상의 프레임(HEADERS, DATA)에 담긴다.
    
    이때, HTTP 헤더는 압축되어 담긴다.
    
    프레임들에 담긴 요청과 응답은 스트림을 통해 보내지며, 한 개의 스트림이 한 쌍의 요청과 응답을 처리한다.
    
    하나의 커넥션 위에 여러 개의 스트림이 동시에 만들어 질 수 있으므로, 여러 개의 요청과 응답을 동시에 처리하는 것이 가능하다.
    
    HTTP/2.0은 스트림에 대한 흐름제어와 우선순위 부여 기능을 제공한다.
    
    HTTP/2.0은 기존의 요청/응답과는 다르게 서버 푸시 모델을 도입했다.
    
    기존 웹 애플리케이션들과의 호환성을 유지하기 위해, HTTP/2.0은 요청과 응답 메시지의 의미를 HTTP/1.1과 같도록 유지하고 있다.
    
    다만 헤더를 표현하는 방식은 변경되었다. Content-Length 헤더는 content-length로 변경되었고 상태줄을 통해 표현하던 404 Not Found는 404 값을 갖는 ‘:status’ 헤더로 표현하게 되었다.
    
    ### 바이너리 프레이밍(binary framing) 계층
    
    바이너리 프레이밍 계층은 HTTP 메시지가 캡슐화되어 클라이언트와 서버 사이에 전송되는 방식을 규정한다.
    
    줄바꿈으로 구분되는 일반 텍스트 HTTP/1.x 프로토콜과 달리, 모든 HTTP/2.0 통신은 더 작은 메시지와 프레임으로 분할되어 바이너리 형식으로 인코딩된다.
    
    HTTP/1.x 클라이언트는 HTTP/2.0 전용 서버를 이해하지 못하며 그 반대도 마찬가지이다. 하지만 필요한 모든 프레이밍 작업을 클라이언트와 서버가 대신 수행해주기 때문에 애플리케이션은 이 모든 변경을 인식하지 않아도 된다.
    
    ### 스트림, 메시지, 프레임
    
    스트림 : HTTP/2.0 커넥션을 통해 클라이언트와 서버 사이에 교환되는 프레임들의 독립된 양방향 시퀀스이다. 하나이상의 메시지가 전달될 수 있다.
  
    ![Untitled](https://github.com/GSLY-CSstudy/tech-interview-CS/assets/71485411/d6545ee6-a50c-45b7-9168-17492a83dd7b)
    
    예를 들어, **1. HTML 문서**와 **2. 해당 문서에서 사용할 Image**를 요청한다고 가정해보자.
    
    Image를 먼저 응답 받아도, 렌더링할 HTML 문서가 처리가 안되면 의미가 없다.
    
    이때 1. HTML 문서의 **우선순위**를 높여서 먼저 응답하고, 2. Image는 이후에 응답하면 더 효율적으로 동작하게 된다.
    
    메시지: 논리적 요청 또는 응답 메시지에 매핑되는 프레임의 전체 시퀀스이다.
    
    프레임: HTTP/2.0에서 통신의 최소 단위이며 각 최소 단위에는 하나의 프레임 헤더가 포함된다. 프레임 헤더는 최소한으로 프레임이 속하는 스트림을 식별한다.
    
    모든 통신은 단일 TCP 연결을 통해 수행되며 전달될 수 있는 양방향 스트림의 수는 제한이 없다.
    
    각 스트림에는 양방향 메시지 전달에 사용되는 고유 식별자와 우선순위 정보(선택사항)이 있다.
    
    각 메시지는 하나의 논리적인 HTTP 요청/응답 메시지이며 하나 이상의 프레임으로 구성된다.
    
    프레임은 통신의 최소 단위이며 특정 유형의 데이터(ex: HTTP 헤더, 메시지 페이로드)를 전달한다.
    
    다른 스트림들의 프레임을 인처리빙한 다음, 각 프레임의 헤더에 삽입된 스트림 식별자를 통해 이 프레임을 다시 조립할 수 있다.  
    
    ![Untitled](https://github.com/GSLY-CSstudy/tech-interview-CS/assets/71485411/101f08ae-0a38-4d26-852d-28551ff1f6be)

    하나의 커넥션에 여러 스트림이 동시에 열릴 수 있으므로 여러 개의 요청을 동시에 보낼 수 있으므로 성능이 뛰어나다.
    
    한 번 사용한 스트림 식별자는 다시 사용할 수 없기 때문에 커넥션을 오래 사용하다보면 스트림에 할당할 수 있는 식별자가 고갈되기도 하는데, 그런 경우엔 커넥션을 다시 맺으면 된다.
    
    ### 서버 푸시
    
    HTTP/2.0은 서버가 단일 클라이언트 요청에 대해 여러 응답을 보낼 수 있다.
    
    리소스를 푸시하려는 서버는 먼저 클라이언트에게 자원을 푸시할 것임을 PUSH_PROMISE 프레임을 보내어 미리 알려주어야 한다.
    
    PUSH_PROMISE 프레임은 리소스를 요청하는 응답 데이터보다 먼저 도착해야 한다.
    
    리소스에 대해 중복 요청이 생성되는 것을 막기 위해 클라이언트는 서버가 어떤 리소스를 푸시할지 알아야 하고, 이러한 요구사항을 충족시키기 위해 약속했던 리소스의 HTTP 헤더만 포함된 모든 PUSH_PROMISE 프레임을 상위 요소의 응답(DATA 프레임)보다 먼저 전송한다.
    
    클라이언트는 PUSH_PROMISE 프레임을 수신한 후에 RST_STREAM 프레임을 보내어 푸시를 거절할 수 있다.
    
    ### Header Compression
    
    기존 HTTP/1.1에서는 이전에 보냈던 요청과 중복되는 Header도 똑같이 전송해서 자원을 낭비했다.
    
    하지만 HTTP/2.0부터는 허프만 코딩을 사용한 HPACK 압축 방식으로 이를 개선했다.
    
    ![Untitled](https://github.com/GSLY-CSstudy/tech-interview-CS/assets/71485411/1912ce79-fe41-44d2-a23c-f67a734ee3be)

    클라이언트와 서버는 각각 Header Table을 관리한다. 
    
    만일 이전 요청과 동일한 필드가 있다면 그 필드는 Table의 index만 보낸다.
    
    변경되는 값은 Huffman Encoding 후 보냄으로써 Header의 크기를 경량화 할 수 있다.
    
    더 구체적인 설명 : [https://blog.bespinglobal.com/post/http1-1-http2/](https://blog.bespinglobal.com/post/http1-1-http2/)
    
    - HOL Blocking 에 대해 설명해 주세요.
        
        웹에서 HOL Blocking을 말할 때에는 두 가지 종류가 있습니다.
        
        1. HTTP에서의 HOL Blocking
            
            HTTP/1.1의 요청-응답 쌍은 항상 순서를 유지하고 동기적으로 수행되어야 합니다.
            
            예를 들어 1개의 TCP 커넥션 상에서 3개의 이미지 a, b, c를 받는 경우 HTTP 요청은
            
            다음과 같이 a → b → c가 된다. 
            
            즉, 하나의 요청이 처리되고 응답을 받은 후에 다음 요청을 보냅니다.
            
            그래서 이전의 요청이 처리되지 않았다면 그 다음 요청은 보낼 수 없습니다.
            
            만약 다음과 같이 a ———————> b —> c 로 a에 관한 응답이 길어지면 어떨까?
            
            b, c가 아무리 빨리 처리되더라도 전체적으로는 느려지게 된다.
            
            이것이 HTTP/1.1의 HOL Blocking이다.
            
            HTTP/1.1의 pipeeelining은 조건부로 요청만 먼저 보내버리는 것으로 이 문제를 회피하는 것처럼 보이지만, 응답을 보낸 순서대로 무조건 받아야 하므로 a의 응답이 막혔을 경우 큰 효과를 보기 어렵다.
            
            이러한 문제를 HTTP/2.0에서 해결하였다.
            
            HTTP/2.0에서 요청은 하나의 연결에서 병렬적으로 보내질 수 있다.
            
            즉 a, b, c가 모두 병렬적으로 요청되고 응답된다.
            
            따라서 a가 시간이 걸리는 처리에서도 b, c는 먼저 받을 수 있는 것이다.
            
            그래서 HTTP/1.1의 HOL Blocking은 HTTP/2에서는 발생하지 않는다.
            
            또한 HTTP/2.0은 접속의 Flow Control과 중요한 자원의 우선순위를 부여하는 Priority를 가지고 있기 때문에 세세한 제어가 가능하다.
            
        2. TCP에서의 HOL Blocking
            
            TCP에서의 HOL Blocking은 HTTP 요청/응답을 TCP 패킷 레벨로 바꾼 거라고 생각하면 된다.
            
            TCP는 패킷을 전송할 때에 전달을 보장하기 때문에 패킷이 손실되면 재전송하게 된다.
            
            그리고 재전송이 발생하면 패킷의 순서가 역전되지 않도록 후속 패킷이 대기한다.
            
            즉, TCP 상에서 3개의 패킷을 보낼 때, 먼저 보낸 패킷에서 손실이 발생하면 뒤도 막히게 된다.
            
            이러한 문제를 TCP에서의 HOL Blocking이라고 한다.
            
            예를 들어, HTTP/2로 다중화된 요청은 TCPDㅔ서는 단순한 패킷이므로 패킷이 막히면 전체가 지연되는 문제를 피할 수 없다. 오히려 1개의 TCP 커넥션으로 전부를 처리하고 있기 때문에 여러 개의 TCP를 사용할 때보다 영향이 클 수도 있다.
            
            실제로 테스트를 통해 패킷 손실률이 2%일 때, HTTP/1.0을 사용할 때 더 나은 성능을 입증했다. 그 이유는 HTTP/1.0은 패킷을 분배할 때, 6개의 TCP 연결을 갖고 있어 손실되는 패킷 없이 사용할 수 있기 때문이다.
            
            이러한 문제는 혼잡제어 알고리즘인 PRR과 BBR을 사용해 완화하였다.
            
            대부분의 TCP구현에서는 CUBIC 알고리즘을 사용한다.
            
            이 알고리즘은 패킷이 손실 될 때 혼잡 제어 창을 절반으로 줄이는 것을 감소시키는 PRR로 강화됐다.
            
            그리고 BBR(Bottleneck Bandwidth and Roundtrip propagation time)은 HTTP/2 연결에 대해 성능을 더 향상시키는 알고리즘이다.
            
            ![Untitled](https://github.com/GSLY-CSstudy/tech-interview-CS/assets/71485411/f9ac4e26-4c75-4e0d-9caf-2820a6f1107f)

            그 이외에 QUIC 프로토콜이 있다.
            
            QUIC(Quick UDP Internet Connections)는 TCP가 아닌 UDP 위에서 자체적으로 재전송 제어 메커니즘을 구성한다. 그리고 이러한 프로토콜은 처음부터 패킷 레벨의 HOL Blocking이 발생하지 않도록 설계되었다.
            
            HTTP/3는 위의 두 HOL  Blocking 문제를 모두 해결한다.
            
            HTTP/3의 가장 큰 특징은 TCP/IP 기반의 애플리케이션 레이어 프로토콜인 HTTP를 UDP 기반의 QUIC 위에 얹은 것이다.
            
            이를 HTTP over QUIC라고 하여 줄여서 HQ라고 한다.
            
            HTTP/2에 있는 프레임, 스트림, 메시지 구조와 기술들은 그대로 HTTP/3로 승계되고 명칭만 HQframe, QPACK등으로 변경되었다.
            
    - HTTP/3.0의 주요 특징에 대해 설명해 주세요.
        1. **QUIC 프로토콜**: HTTP/3.0은 UDP 기반의 QUIC 프로토콜을 사용하여 통신합니다. 이는 TCP의 한계를 극복하고 최적화된 연결을 제공합니다. QUIC는 TCP와 TLS의 기능을 모두 구현한 프로토콜로, TCP의 HOLB 문제를 해결하고 UDP의 빠른 전송 속도를 유지합니다.
        2. **TCP 대신 UDP**: TCP는 전송 지연 및 패킷 손실 문제로 인해 성능 저하를 가져올 수 있습니다. UDP는 TCP보다 빠른 속도를 제공하며, 연결 지향성이나 패킷의 무결성에 대한 확인 과정을 거치지 않습니다.
        3. **HOLB 문제 해결**: HTTP/3.0은 TCP의 HOLB 문제를 해결하기 위해 UDP를 사용합니다. QUIC 프로토콜은 데이터 스트림을 독립적으로 처리하여 HOLB 문제를 완화합니다.
        4. **빠른 연결 설정**: QUIC은 핸드쉐이크 과정을 최소화하여 연결 설정 시간을 단축합니다. 최초 연결 설정에는 1 RTT만 소요되며, 추가적인 연결에서는 0 RTT로 바로 통신이 가능합니다.
        5. **보안 강화**: HTTP/3.0은 QUIC 내에 TLS 암호화를 기본적으로 사용하여 보안성을 강화합니다. TCP와 달리 헤더 영역도 암호화되므로 더 높은 보안 수준을 제공합니다.
        6. **네트워크 변경에 대한 유연성**: QUIC은 Connection ID를 사용하여 연결을 식별하므로, 클라이언트 IP가 변경되어도 연결이 유지됩니다. 따라서 네트워크 변경 시에도 연결이 유지되어 중단 없이 통신이 가능합니다.
        
- **TCP와 UDP의 차이에 대해 설명해 주세요.**
    
    ### TCP(Transmission Control Protocol)
    
    TCP는 인터넷 상에서 데이터를 메시지의 형태로 보내기 위해 IP와 함께 사용하는 프로토콜입니다.
    
    일반적으로 TCP와 IP를 함께 사용하는데, IP가 데이터의 배달을 처리한다면 TCP는 패킷을 추적 및 관리하게 됩니다. TCP는 연결형 서비스를 지원하는 프로토콜로 인터넷 환경에서 기본으로 사용합니다.
    
    ![Untitled](https://github.com/GSLY-CSstudy/tech-interview-CS/assets/71485411/3a61645d-c355-4c97-8479-d97fee6f0c73)

    TCP의 특징
    
    - 연결 지향 방식으로 패킷 교환 방식을 사용한다.(가상회선방식이 아님)
        
        TCP가 연결 지향 방식이라는 것은 패킷을 전송하기 위해 논리적 경로를 배정한다는 말입니다.
        
    - 3-way handshaking 과정을 통해 연결을 설정하고 4-way handshaking을 통해 해제한다.
        
        3-way handshaking 과정은 목적지와 수신지를 확실히 하여 정확한 전송을 보장하기 위해서 세션을 수립하는 과정을 의미합니다.
        
    - 흐름 제어 및 혼잡 제어를 한다.
        
        흐름제어는 데이터를 송신하는 곳과 수신하는 곳의 데이터 처리 속도를 조절하여 수신자의 버퍼 오버플로우를 방지하는 것입니다. 예를 들어 송신하는 곳에서 감당이 안되게 데이터를 빠르게 많이 보내면 수신자에서 문제가 발생하기 때문입니다. 혼잡제어는 네트워크 내의 패킷 수가 넘치게 증가하지 않도록 방지하는 것입니다. 만약 정보의 소통량이 과다하면 패킷을 조금만 전송하여 혼잡 붕괴 현상이 일어나는 것을 막습니다.
        
        - TCP의 혼잡 제어 처리 방법에 대해 설명해 주세요.
            
            TCP의 혼잡 제어(congestion control)는 네트워크의 혼잡을 방지하고 효율적인 데이터 전송을 위해 전송 속도를 조절하는 메커니즘입니다. 이를 통해 네트워크의 혼잡을 감지하고 회피함으로써 데이터의 손실을 최소화하고 신뢰성을 보장합니다. TCP의 혼잡 제어는 다음과 같은 과정을 거칩니다:
            
            1. **Congestion Window (혼잡 윈도우)**: TCP는 혼잡 상태를 파악하기 위해 혼잡 윈도우 크기를 조절합니다. 혼잡 윈도우는 현재 네트워크가 수용할 수 있는 데이터의 양을 나타냅니다. 초기에는 작은 크기로 시작하여 네트워크 상황에 따라 조절됩니다.
            2. **Slow Start**: TCP의 혼잡 제어는 Slow Start라는 초기화 단계를 포함합니다. 클라이언트는 초기에 전송할 수 있는 패킷 수를 점진적으로 늘려가며 네트워크의 용량을 살피는 과정입니다. 처음에는 혼잡 윈도우 크기를 작게 설정하고, 각각의 ACK를 받을 때마다 윈도우 크기를 2배씩 증가시킵니다.
            3. **Congestion Avoidance (혼잡 회피)**: 혼잡 윈도우가 일정 크기 이상으로 커지면 Slow Start가 종료되고 Congestion Avoidance 단계로 전환됩니다. 이 단계에서는 혼잡 윈도우를 선형적으로 증가시키는 대신, 혼잡 윈도우를 각각의 ACK마다 조금씩 증가시킵니다. 이를 통해 네트워크 혼잡을 방지하고 안정적인 전송 속도를 유지합니다.
            4. **Fast Retransmit and Fast Recovery**: 패킷 손실이 감지되면 TCP는 빠른 재전송과 빠른 복구 기법을 사용하여 재전송을 즉시 시도합니다. 이를 통해 데이터 전송의 효율성을 향상시키고 혼잡 윈도우 크기를 적절히 조절합니다.
            5. **Timeout**: 타임아웃이 발생하면 혼잡 윈도우 크기를 재설정하고 Slow Start로 돌아갑니다. 이는 네트워크에서 패킷이 손실되었거나 혼잡 상태가 지속되고 있는 경우에 적용됩니다.
            
            네트워크에서 클라이언트와 서버 간에 파일을 전송하는 상황을 가정해보겠습니다. 클라이언트는 서버에게 파일을 요청하고, 서버는 이에 응답하여 파일을 전송합니다. 이때 TCP의 혼잡 제어 과정을 예시를 통해 설명하겠습니다.
            
            1. **Slow Start 시작**:
                - 클라이언트가 서버에게 파일을 요청합니다. 클라이언트의 혼잡 윈도우 크기는 초기에 작게 설정됩니다. 예를 들어, 혼잡 윈도우 크기는 1로 시작합니다.
                - 서버는 클라이언트에게 파일 데이터를 패킷으로 분할하여 전송합니다. 이때, 클라이언트는 혼잡 윈도우 크기에 따라 한 번에 하나의 패킷을 받습니다.
                - 클라이언트는 패킷을 받으면 해당 패킷이 도착했음을 확인하기 위해 ACK를 반환합니다.
                - 서버는 ACK를 받으면 혼잡 윈도우 크기를 2배로 증가시킵니다. 따라서 다음 패킷을 전송할 때 클라이언트는 2개의 패킷을 받을 수 있습니다.
            2. **혼잡 윈도우 크기 증가**:
                - 서버는 ACK를 계속해서 받으면 혼잡 윈도우 크기를 계속해서 늘려나갑니다. 클라이언트는 혼잡 윈도우 크기에 따라 받을 수 있는 패킷의 수를 점진적으로 증가시킵니다.
                - 이 과정을 통해 네트워크의 용량을 파악하고 최대 전송 가능한 속도에 도달하기까지 혼잡 윈도우 크기를 증가시킵니다.
            3. **Congestion Avoidance로 전환**:
                - 혼잡 윈도우 크기가 일정 값 이상으로 증가하면 Congestion Avoidance로 전환됩니다.
                - Congestion Avoidance 단계에서는 각각의 ACK마다 혼잡 윈도우 크기를 조금씩 증가시킵니다. 이를 통해 네트워크 혼잡을 방지하고 안정적인 전송 속도를 유지합니다.
            4. **혼잡 감지 및 재조정**:
                - 네트워크에서 패킷 손실이 발생하거나 네트워크 혼잡을 감지하면, TCP는 혼잡 윈도우 크기를 줄이고 Slow Start로 돌아갑니다.
                - 이를 통해 네트워크 혼잡을 회피하고 안정적인 데이터 전송을 유지합니다.
    - 높은 신뢰성을 보장한다.
        - TCP가 신뢰성을 보장하는 방법에 대해 설명해 주세요.
            
            TCP는 연결형 서비스로 신뢰성을 보장합니다. 이러한 신뢰성을 보장하기 위해 3-way handshaking 과정이 사용되고 데이터의 흐름제어나 혼잡제어와 같은 기능도 사용합니다.
            
            그렇기에 TCP는 연속성보다 신뢰성 있는 전송이 중요할 때에 사용하는 프로토콜 입니다.
            
            예를 들어 파일 전송과 같은 경우에 사용됩니다.
            
            1. **Acknowledgment (확인 응답)**: TCP에서 데이터를 전송한 후 수신자는 데이터를 제대로 받았음을 확인하기 위해 확인 응답(ACK)를 송신자에게 전송합니다. 만약 송신자가 일정 시간 동안 확인 응답을 받지 못하면 해당 데이터를 다시 전송합니다. 이로써 데이터의 손실을 방지하고 전송의 신뢰성을 보장합니다.
            2. **Sequencing (순서 보장)**: TCP는 데이터의 순서를 보장하기 위해 시퀀스 번호를 사용합니다. 각각의 TCP 세그먼트에는 시퀀스 번호가 할당되어 있고, 수신자는 이를 통해 데이터를 올바른 순서로 재조립합니다.
            3. **Retransmission (재전송)**: 데이터가 손실되거나 손상된 경우, TCP는 일정 시간 동안 재전송 요청을 기다린 후 데이터를 다시 전송합니다. 이를 통해 데이터의 손실을 복구하고 전송의 신뢰성을 유지합니다.
            4. **Flow control (흐름 제어)**: TCP는 수신자의 수용 가능한 속도에 따라 데이터의 전송 속도를 조절하여 네트워크 혼잡을 방지합니다. 이를 통해 네트워크 혼잡으로 인한 데이터 손실을 최소화하고 신뢰성을 유지합니다.
            5. **Congestion control (혼잡 제어)**: TCP는 네트워크의 혼잡 상태를 감지하고 전송 속도를 조절하여 네트워크 혼잡을 완화합니다. 혼잡한 네트워크에서 데이터의 손실을 방지하고 전송의 신뢰성을 유지합니다.
    - UDP보다 속도가 느리다.
    - 전이중(Full-Duplex), 점대점(Point to Point)방식이다.
    
    TCP 서버의 특징
    
    - 서버소켓은 연결만을 담당한다.
    - 연결과정에서 반환된 클라이언트 소켓은 데이터의 송수신에 사용된다.
    - 서버와 클라이언트는 1대1로 연결된다.
    - 스트림 전송으로 전송 데이터의 크기가 무제한이다.
    - 패킷에 대한 응답을 해야하기 때문에 성능이 낮다.(시간지연, CPU 소모)
    - 데이터가 손실된 경우 재전송 요청을 하므로 Streaming 서비스에 불리하다.
    
    - 왜 HTTP는 TCP를 사용하나요?
        1. **신뢰성**: HTTP는 웹 페이지, 이미지, 비디오 등의 다양한 리소스를 전송하는 데 사용됩니다. 이러한 리소스는 정확하고 완전하게 전송되어야 합니다. TCP는 패킷 손실이나 손상 시 재전송을 수행하여 데이터의 신뢰성을 보장합니다. 따라서 HTTP의 특성상 정확하고 완전한 데이터 전송이 요구되는 경우 TCP를 사용함으로써 데이터 손실을 최소화할 수 있습니다.
        2. **순서 보장**: 웹 브라우저가 웹 페이지의 여러 리소스를 동시에 요청할 수 있습니다. 이러한 요청들은 서버로부터 전송된 순서대로 웹 브라우저에게 전달되어야 합니다. TCP는 데이터의 전송 순서를 보장하므로, HTTP 통신에서는 클라이언트가 보낸 요청과 서버로부터 받은 응답이 올바른 순서로 처리될 수 있습니다.
        3. **흐름 제어 및 혼잡 제어**: HTTP는 TCP의 흐름 제어 및 혼잡 제어 기능을 활용하여 네트워크 리소스를 효율적으로 관리합니다. TCP는 데이터 전송 속도를 조절하고 네트워크 혼잡을 감지하여 데이터 손실을 최소화합니다. 이는 HTTP 통신에서 여러 클라이언트가 동시에 서버에 접속하는 경우에도 안정적인 통신을 유지할 수 있도록 도와줍니다.
        4. **연결 지향성**: HTTP는 클라이언트와 서버 간의 상태를 유지하지 않는 stateless 프로토콜입니다. 하지만 TCP는 연결 지향적인 프로토콜로, 클라이언트와 서버 간의 연결을 설정하고 데이터를 주고받은 후 연결을 종료합니다. 이는 HTTP의 요청-응답 모델과 잘 어울리며, 클라이언트와 서버 간의 안정적인 통신을 지원합니다.
        
    
    ### UDP(User Datagram Protocol)
    
    UDP는 데이터를 데이터그램 단위로 처리하는 프로토콜입니다.
    
    여기서 데이터그램이란 독립적인 관계를 지니는 패킷이라는 뜻입니다.
    
    UDP의 동작방식은 TCP와 달리 비연결형입니다. 즉, 연결을 위해 할당되는 논리적인 경로가 없습니다.
    
    그렇기 때문에 각각의 패킷은 다른 경로로 전송되고 각각의 패킷은 독립적인 관계를 지니게 됩니다.
    
    ![Untitled](https://github.com/GSLY-CSstudy/tech-interview-CS/assets/71485411/7c526ff9-0e19-4a60-a17c-70554ff9a21f)

    이렇게 데이터를 서로 다른 경로로 독립적으로 처리하게 됩니다.
    
    UDP의 특징
    
    - 비연결형 서비스로 데이터그램 방식을 제공한다.
    - 정보를 주고 받을 때 정보를 보내거나 받는다는 신호절차를 거치지 않는다.
    - UDP 헤더의 CheckSum 필드를 통해 최소한의 오류만 검출한다.
    - 신뢰성이 낮다.
    - TCP보다 속도가 빠르다.
    
    UDP는 비연결형 서비스이기 때문에 연결을 설정하고 해제하는 과정이 존재하지 않습니다.
    
    서로 다른 경로로 독립적으로 처리함에도 패킷에 순서를 부여하여 재조립을 하거나 흐름 제어 또는 혼잡 제어와 같은 기능도 처리하지 않기에 TCP보다 속도가 빠르며 네트워크 부하가 적다는 장점이 있지만 신뢰성 있는 데이터의 전송을 보장하지는 못합니다.
    
    그렇기 때문에 신뢰성보다는 연속성이 중요한 서비스 예를 들면 실시간 서비스(streaming)에 자주 사용됩니다.
    
     UDP 서버의 특징
    
    - UDP에는 연결 자체가 없어서(connect 함수 불필요) 서버 소켓과 클라이언트 소켓의 구분이 없다.
    - 소켓 대신 IP를 기반으로 데이터를 전송한다.
    - 서버와 클라이언트는 1대1, 1대N, N대M 등으로 연결될 수 있다.
    - 데이터그램(메세지) 단위로 전송되며 그 크기는 65545바이트로, 크기가 초과하면 잘라서 보낸다.
    - 흐름제어(flow control)가 없어서 패킷이 제대로 전송되었는지, 오류가 없는지 확인할 수 없다.
    - 파일 전송과 같은 신뢰성이 필요한 서비스보다 성능이 중요시 되는 경우에 사용된다.
    
    - 왜 HTTP/3 에서는 UDP를 사용하나요? 위에서 언급한 UDP의 문제가 해결되었나요?
        
        HTTP/3에서 UDP를 사용하는 이유는 주로 성능 및 연결의 효율성을 개선하기 위해서입니다. UDP를 사용하면 다음과 같은 이점이 있습니다:
        
        1. **커넥션리스(Connectionless) 프로토콜**: UDP는 TCP와는 달리 연결 설정 및 해제 과정이 없습니다. 이는 서버와 클라이언트 간의 핸드셰이크 과정이 필요 없고, 데이터를 보내기 위해 간단한 패킷만으로 통신이 가능하다는 것을 의미합니다. 이로 인해 핸드셰이크로 인한 지연이나 오버헤드를 최소화할 수 있습니다.
        2. **멀티플렉싱(Multiplexing) 및 병렬 전송**: UDP를 이용한 프로토콜인 QUIC(HTTP/3의 기초가 되는 프로토콜)는 멀티플렉싱을 통해 하나의 연결에서 여러 개의 스트림을 동시에 전송할 수 있습니다. 이는 여러 요청 및 응답을 병렬로 처리하여 네트워크 사용률을 향상시키고 대기 시간을 줄여줍니다.
        3. **혼잡 제어 및 패킷 손실 복구**: QUIC은 TCP와 동일한 혼잡 제어 알고리즘을 사용하며, 패킷 손실을 감지하고 복구하는 기능을 지원합니다. 따라서 UDP를 사용하더라도 혼잡 제어와 신뢰성은 유지됩니다.
        4. **프록시 및 NAT 트래버셜**: UDP를 사용하면 프록시 및 NAT(Network Address Translation) 트래버셜이 더욱 간편해집니다. UDP는 TCP와는 다르게 연결 지향적인 특성이 없으므로 NAT 트래버셜이 더욱 용이합니다.
        
    - 그런데, 브라우저는 어떤 서버가 TCP를 쓰는지 UDP를 쓰는지 어떻게 알 수 있나요?
        
        브라우저는 일반적으로 DNS(Domain Name System)를 통해 서버의 주소를 확인하고, 이후 해당 서버와의 통신에 사용될 프로토콜을 결정합니다. 주로 HTTP/HTTPS 프로토콜을 사용하는 웹 페이지의 경우, 브라우저는 서버와의 통신에 TCP를 사용합니다. 이는 HTTP/HTTPS 프로토콜이 TCP를 기반으로 동작하기 때문입니다.
        
        그러나 HTTP/3와 같은 경우, 브라우저는 먼저 DNS를 통해 서버의 주소를 확인한 후, 해당 서버가 QUIC을 지원하는지 확인합니다. 이를 확인하기 위해 서버의 호스트 이름과 포트 번호 뒤에 ":quic"이라는 접미사를 붙여서 연결을 시도합니다. 만약 서버가 QUIC을 지원한다면, 브라우저와 서버 간에 QUIC 연결이 설정되고 UDP를 통해 데이터가 전송됩니다.
        
        따라서 브라우저는 서버와의 연결 설정 과정에서 서버가 TCP를 사용하는지 UDP를 사용하는지를 결정하며, 이는 주로 사용되는 프로토콜에 따라 달라집니다.
        
        크롬 브라우저에서는 개발자 도구(DevTools)를 통해 서버와의 연결에 사용되는 프로토콜을 확인할 수 있습니다. 아래는 크롬 브라우저에서 사용 가능한 방법입니다:
        
        1. **개발자 도구 열기**: 크롬 브라우저에서 웹 페이지를 열고, 우측 상단의 메뉴 버튼을 클릭한 후 "도구 더 보기" > "개발자 도구"를 선택하여 개발자 도구를 엽니다. 단축키로는 "Ctrl + Shift + I" (Windows 및 Linux) 또는 "Cmd + Opt + I" (Mac)를 사용할 수 있습니다.
        2. **네트워크 탭으로 이동**: 개발자 도구가 열리면 상단 메뉴에서 "네트워크(Network)" 탭을 선택합니다.
        3. **페이지 새로고침**: 개발자 도구의 네트워크 탭에서 웹 페이지를 새로고침합니다. 이렇게 하면 웹 페이지에서 로드되는 모든 자원들에 대한 네트워크 요청과 응답이 개발자 도구에 표시됩니다.
        4. **프로토콜 확인**: 네트워크 탭에서 특정 자원(예: HTML 파일, CSS 파일, 이미지 등)을 선택하면 해당 자원의 세부 정보를 확인할 수 있습니다. 세부 정보에서 "프로토콜" 항목을 확인하여 사용된 프로토콜(TCP 또는 UDP)을 확인할 수 있습니다
        
    - 본인이 새로운 통신 프로토콜을 TCP나 UDP를 사용해서 구현한다고 하면, 어떤 기준으로 프로토콜을 선택하시겠어요?
        1. **신뢰성 요구 사항**: 데이터의 완전성과 순서를 보장해야 하는 경우에는 TCP를 선택합니다. TCP는 데이터 전송의 신뢰성을 보장하기 위해 패킷 손실 및 손상을 감지하고 재전송합니다.
        2. **전송 속도와 지연**: 데이터의 전송 속도가 중요하고 손실이 발생하더라도 재전송이 필요 없는 경우에는 UDP를 선택합니다. UDP는 TCP보다 속도가 빠르며, 실시간 통신(예: 영상 스트리밍, 음성 통화)에 적합합니다.
        3. **연결 지향성**: 연결 지향적인 프로토콜이 필요한 경우에는 TCP를 선택합니다. TCP는 연결을 설정하고 종료하는 과정을 거칩니다. 그에 반해 UDP는 연결을 설정하지 않고 데이터를 즉시 전송합니다.
        4. **네트워크 환경**: 네트워크의 혼잡 정도와 패킷 손실률을 고려하여 프로토콜을 선택합니다. TCP는 혼잡 제어 및 패킷 복구 기능을 제공하여 신뢰성을 보장하지만, UDP는 이러한 기능을 제공하지 않습니다.
        5. **프로토콜의 복잡성**: 프로토콜의 복잡성과 구현 난이도도 고려해야 합니다. UDP는 단순하고 가벼운 프로토콜이지만, TCP는 연결 설정 및 혼잡 제어와 같은 복잡한 기능을 제공합니다.
    
    ![Untitled](https://github.com/GSLY-CSstudy/tech-interview-CS/assets/71485411/10c19217-3a32-4afc-ac5d-6b8353a5f82a)

    교환 방식
    
    ![Untitled](https://github.com/GSLY-CSstudy/tech-interview-CS/assets/71485411/6be7902e-4cf5-4935-aa6e-9e7ad0541495)

    TCP Flow
    
    ![Untitled](https://github.com/GSLY-CSstudy/tech-interview-CS/assets/71485411/4bc8bc7a-a83f-479c-b4d7-7ecd9e5d57f8)

    UDP Flow
    
- **Checksum이 무엇인가요?**
    
    Checksum(체크섬)은 데이터의 무결성을 확인하기 위해 사용되는 값입니다. 
    
    데이터를 전송 또는 저장하기 전에 체크섬을 계산하여 데이터에 첨부하고, 수신 측에서는 데이터를 받은 후에 체크섬을 다시 계산하여 송신 측이 보낸 체크섬 값과 비교합니다. 
    
    이를 통해 데이터가 전송 중에 손상되었는지를 감지할 수 있습니다.
    
    일반적으로 체크섬은 데이터의 모든 비트를 합산하여 생성됩니다. 송신자는 데이터를 보낼 때 해당 데이터의 체크섬 값을 계산하고, 이 값을 데이터와 함께 전송합니다. 
    
    수신자는 데이터를 받은 후에 체크섬 값을 다시 계산하고, 송신자가 전송한 체크섬 값과 비교합니다. 만약 두 값이 다르다면, 데이터가 손상되었다는 것을 의미합니다.
    
    Checksum은 주로 네트워크 통신에서 데이터의 무결성을 보장하기 위해 사용됩니다. 
    
    예를 들어, TCP와 UDP 프로토콜은 데이터 전송 중에 발생한 손상을 감지하기 위해 Checksum을 사용합니다. 또한 파일 전송이나 데이터 저장 시에도 Checksum을 사용하여 데이터의 정확성을 확인할 수 있습니다.
    
    1. **송신자의 과정**:
        - Alice가 Bob에게 메시지를 보내려고 합니다. 이 메시지는 TCP나 UDP 프로토콜을 통해 전송됩니다.
        - Alice는 메시지를 보내기 전에 해당 메시지의 체크섬 값을 계산합니다.
        - 예를 들어, Alice가 전송할 메시지의 데이터가 "Hello, Bob!"이라고 가정하고, 이 데이터의 체크섬 값을 계산합니다.
    2. **체크섬 계산**:
        - Alice는 "Hello, Bob!" 메시지의 각 바이트의 값을 합산하여 체크섬 값을 계산합니다.
        - 이 과정은 각 문자의 ASCII 값을 더하는 것으로 간단히 할 수 있습니다. 예를 들어, 'H'는 ASCII 값이 72이므로 72를 더하고, 'e'는 ASCII 값이 101이므로 101을 더합니다.
        - 계산된 값은 일반적으로 16비트 또는 32비트의 값으로 표현됩니다.
    3. **체크섬 값 전송**:
        - Alice는 메시지와 함께 계산된 체크섬 값을 포함하여 메시지를 Bob에게 보냅니다.
    4. **수신자의 과정**:
        - Bob은 Alice로부터 메시지를 받았습니다. 메시지는 TCP/UDP 헤더와 데이터로 구성됩니다.
        - Bob은 수신된 데이터의 체크섬 값을 계산합니다.
        - 이를 위해 Bob은 수신된 데이터의 각 바이트의 값을 합산하여 체크섬 값을 계산합니다.
    5. **체크섬 검사**:
        - Bob은 계산된 체크섬 값과 송신자인 Alice가 보낸 체크섬 값을 비교합니다.
        - 만약 두 값이 일치한다면, 데이터는 손상되지 않았다고 가정하고 처리를 계속합니다.
        - 하지만 두 값이 다르다면, 데이터에 오류가 있을 수 있다고 판단하고, 이에 대한 적절한 조치를 취할 수 있습니다.
    
    - TCP와 UDP 중 어느 프로토콜이 Checksum을 수행할까요?
        
        TCP와 UDP 모두 페이로드의 무결성을 확인하기 위해 Checksum을 수행합니다. Checksum은 데이터의 오류를 감지하기 위한 방법으로, 데이터를 전송하기 전에 송신자가 체크섬 값을 계산하여 전송 데이터에 포함시킵니다. 수신자는 받은 데이터의 체크섬 값을 다시 계산하고 송신자가 전송한 체크섬 값과 비교하여 오류를 감지합니다.
        
        따라서 TCP와 UDP는 모두 데이터의 무결성을 확인하기 위해 Checksum을 수행하며, 데이터 전송의 신뢰성을 보장하기 위해 이를 사용합니다.
        
    - 그렇다면, Checksum을 통해 오류를 정정할 수 있나요?
        
        Checksum을 통해 오류를 정정하는 것은 아닙니다. Checksum은 오류를 감지하는데 사용되며, 오류가 발견되면 해당 데이터 패킷을 버리거나 다시 요청하여 정정하는 작업은 상위 계층에서 수행됩니다.
        
        TCP의 경우, 수신자가 데이터의 Checksum을 계산하고 이 값이 송신자가 보낸 Checksum 값과 다를 경우 오류가 발생했다고 판단합니다. 이런 경우 TCP는 송신자에게 해당 데이터를 다시 전송하도록 요청합니다. 이로써 오류를 정정할 수 있습니다.
        
        UDP의 경우, 오류가 발견되면 UDP는 오류를 정정하는 메커니즘이 내장되어 있지 않습니다. 오류를 감지한 UDP는 오류가 발생한 데이터를 그대로 무시하고 버리게 됩니다. 이는 UDP의 특징 중 하나로, UDP는 오류 검사를 감지하는 기능만 제공하고 오류를 정정하지는 않습니다.
        
        따라서 Checksum은 데이터의 무결성을 보장하는데 사용되지만, 오류를 정정하는데는 사용되지 않습니다. 오류 정정은 상위 프로토콜이나 응용 프로그램에서 수행됩니다.
        
    
- **3-Way Handshake에 대해 설명해 주세요.**
    
    3-Way Handshake는 TCP/IP 프로토콜 스택에서 두 호스트 간에 연결을 설정하기 위한 과정입니다. 
    
    이 과정은 세 단계의 메시지 교환으로 이루어집니다. 
    
    간단히 말해서, 클라이언트가 서버에게 연결을 요청하고, 서버가 이를 수락하며 연결을 설정하는 과정입니다.
    
    3-Way Handshake 단계는 다음과 같습니다:
    
    1. **SYN(Synchronize)**
        - 클라이언트가 서버에게 연결을 요청하는 SYN 패킷을 보냅니다.
        - 클라이언트가 클라이언트 포트 번호와 초기 순차 번호를 포함하여 SYN 패킷을 보냅니다. 이 순차 번호는 이후 데이터 전송에 사용될 것입니다.
    2. **SYN-ACK(Synchronize-Acknowledgment)**
        - 서버는 클라이언트의 SYN 패킷을 받으면, 연결 요청을 수락하는 ACK와 SYN이 설정된 패킷을 보냅니다.
        - 서버는 클라이언트 포트 번호와 서버 포트 번호를 지정하고, 자체적으로 초기 순차 번호를 할당합니다.
    3. **ACK(Acknowledgment)**
        - 클라이언트는 서버로부터의 SYN-ACK 패킷을 받으면, 서버가 연결 요청을 수락했다는 것을 확인하기 위해 ACK 패킷을 보냅니다.
        - 이 패킷은 서버에게 연결 요청에 대한 응답임과 동시에 데이터 전송 준비가 되었음을 나타냅니다.
        
    - ACK, SYN 같은 정보는 어떻게 전달하는 것 일까요?
        
        ACK와 SYN 같은 TCP 제어 정보는 TCP 헤더에 포함되어 데이터와 함께 전송됩니다. 
        
        TCP는 IP 프로토콜 위에서 동작하며, TCP 헤더는 IP 헤더의 데이터 부분에 포함됩니다.
        
        TCP 헤더는 20바이트로 구성되며, 여기에는 목적지 및 출발지 포트 번호, 순차 번호, 확인 번호, 플래그 등이 포함됩니다. 
        
        예를 들어, SYN 플래그가 설정된 TCP 세그먼트는 연결 설정 요청을 나타내고, ACK 플래그가 설정된 세그먼트는 확인 메시지를 나타냅니다.
        
        전송하는 TCP 세그먼트에 포함된 제어 정보는 수신자에게 해당 정보를 전달하고, 수신자는 이를 확인하거나 적절히 응답하여 통신을 원활하게 합니다. 이를 통해 TCP는 신뢰성 있는 데이터 전송을 보장하고, 연결 설정 및 해제 등의 제어 정보를 효율적으로 교환할 수 있습니다.
        
    - 2-Way Handshaking 를 하지않는 이유에 대해 설명해 주세요.
        
        2-Way Handshaking은 클라이언트와 서버 간에 단순한 확인 메시지를 교환하는 것으로, 일반적으로 TCP/IP 프로토콜 스택에서는 사용되지 않습니다. 
        
        2-Way Handshaking에서는 클라이언트가 서버에게 요청 메시지를 보내고, 서버가 이를 받은 후에 확인 메시지를 보내는 것으로 두 번의 메시지 교환이 이루어집니다. 이러한 방식은 연결 설정을 간단하게 할 수 있지만, 신뢰성 있는 통신을 보장하기에는 불충분합니다. 예를 들어, 클라이언트가 서버에게 요청을 보내고 확인 메시지를 받았다고 가정해 봅시다. 그러나 이 확인 메시지가 중간에 손실되었다면, 클라이언트는 서버가 요청을 받았다고 오해할 수 있습니다. 이러한 경우에는 실제로 연결이 설정되지 않았음에도 불구하고 클라이언트가 데이터를 전송하려고 할 수 있습니다.
        
        이와 같은 이유로 TCP/IP 프로토콜 스택은 신뢰성 있는 연결 설정을 위해 3-Way Handshake를 사용합니다. 3-Way Handshake에서는 클라이언트가 서버에게 연결 요청을 보내고, 서버가 이를 수락하는데 필요한 정보를 클라이언트에게 보낸 후에 클라이언트가 이를 확인하는 과정을 거칩니다. 이를 통해 양쪽 간에 연결 설정이 안전하게 이루어지고, 데이터 전송 전에 두 호스트 간의 상태를 확인할 수 있습니다.
        
    - 두 호스트가 동시에 연결을 시도하면, 연결이 가능한가요? 가능하다면 어떻게 통신 연결을 수행하나요?
        
        두 호스트가 동시에 연결을 시도하면, 일반적으로는 두 호스트 간에 중복된 연결이 설정될 수 있습니다. 이는 TCP/IP 프로토콜 스택의 3-Way Handshake 과정에서 발생할 수 있는 상황입니다.
        
        예를 들어, 호스트 A와 호스트 B가 동시에 서로에게 연결을 시도한다고 가정해 봅시다. 각각의 호스트는 SYN 패킷을 보내고, 상대방으로부터 SYN-ACK 패킷을 받을 것입니다. 그럼 각 호스트는 수신한 SYN-ACK 패킷에 대한 ACK를 보내고, 이렇게 하면 각 호스트 간에 중복된 연결이 설정됩니다.
        
        이러한 상황은 일시적인 문제로 여겨질 수 있으며, 대부분의 경우에는 이후 데이터 전송 과정에서 처리될 수 있습니다. 예를 들어, 두 호스트 간에 중복된 연결이 설정되더라도, 이후 데이터 전송 과정에서는 TCP 프로토콜의 패킷 시퀀스 번호를 통해 중복된 패킷을 걸러내고 처리할 수 있습니다.
        
        그러나 중복된 연결이 발생하는 것은 효율적인 네트워크 리소스 사용을 방해하고, 응용 프로그램에서 불필요한 오버헤드를 초래할 수 있으므로 최대한 피해야 합니다. 이를 위해 일부 프로토콜은 중복된 연결을 방지하기 위한 추가적인 메커니즘을 도입하기도 합니다.
        
    - SYN Flooding 에 대해 설명해 주세요.
        
        SYN Flooding은 네트워크 공격의 한 형태로, TCP 3-Way Handshake 과정에서 발생하는 취약점을 이용하여 공격하는 것입니다. 이 공격은 서비스 거부(Denial of Service, DoS) 공격의 한 유형으로 사용되며, 네트워크 리소스를 고갈시켜 정상적인 서비스를 제공하는 것을 방해합니다.
        
        SYN Flooding 공격의 과정은 다음과 같습니다:
        
        1. **공격자가 대상 서버에 대량의 SYN 패킷을 보냅니다.** 
            
            공격자는 대상 서버의 IP 주소를 송신자로 설정하고, 대상 포트로 연결을 시도하는 많은 수의 SYN 패킷을 보냅니다.
            
        2. **대상 서버는 SYN-RCVD 상태로 진입합니다.** 
            
            SYN 패킷을 수신한 대상 서버는 연결 요청을 받았음을 의미하는 SYN-RCVD 상태로 진입합니다. 이후 대상 서버는 연결을 수락하거나 거부할 준비를 합니다.
            
        3. **대상 서버는 SYN-ACK 응답을 보냅니다.** 
            
            대상 서버는 SYN 패킷을 수신한 후에 SYN-ACK 응답을 보냅니다. 이 응답은 클라이언트에게 연결을 수락할 준비가 되었음을 알려주는 것입니다.
            
        4. **공격자는 ACK 응답을 보내지 않습니다.**
            
            SYN-ACK 응답을 받은 공격자는 ACK 응답을 보내지 않고, 대상 서버의 연결을 확인하지 않습니다. 대상 서버는 이후에도 계속해서 SYN-RCVD 상태로 유지되며, 대기열이 가득 차게 됩니다.
            
        5. **대상 서버는 대기열이 가득 차 연결을 거부합니다.** 
            
            SYN-RCVD 상태의 연결 대기열이 가득 차면, 대상 서버는 추가적인 연결 요청을 거부하게 됩니다. 이로 인해 정상적인 클라이언트의 연결 요청도 처리되지 못하고, 서비스가 거부되는 현상이 발생합니다.
            
        
        이러한 방식으로 공격자는 대상 서버의 네트워크 리소스를 소비하고, 정상적인 서비스를 제공하는 것을 방해합니다. 이를 방지하기 위해서는 방화벽이나 인트라넷 보호장치를 통해 SYN 패킷의 수를 제한하거나, SYN 쿠키(SYN Cookies)와 같은 방어 메커니즘을 사용하여 대응할 수 있습니다.
        
    - 위 질문과 모순될 수 있지만, 3-Way Handshake의 속도 문제 때문에 이동 수를 줄이는 0-RTT 기법을 많이 적용하고 있습니다. 어떤 방식으로 가능한 걸까요?
        
        0-RTT(Zero Round Trip Time) 기법은 TLS 1.3와 같은 프로토콜에서 사용되는 기술로, 3-Way Handshake의 속도 문제를 해결하고 통신 지연을 줄이기 위해 도입되었습니다. 이를 가능하게 하는 방식은 다음과 같습니다:
        
        1. **Pre-shared Key (PSK)를 사용한 재사용 세션 티켓**: 클라이언트와 서버 간에 이미 공유된 Pre-shared Key(사전 공유 키)를 사용하여 세션 티켓을 생성하고 저장합니다. 클라이언트는 이 세션 티켓을 이용하여 이전에 설정된 세션 정보를 서버에게 제공합니다. 이를 통해 서버는 클라이언트의 요청을 미리 처리하고, 새로운 연결을 설정하는데 필요한 3-Way Handshake 단계를 건너뛸 수 있습니다.
        2. **Early Data(0-RTT Data)**: 클라이언트가 새로운 연결을 설정하는 동안, 클라이언트는 서버에게 미리 보낼 데이터를 함께 전송할 수 있습니다. 이를 통해 클라이언트는 3-Way Handshake 완료 후에도 즉시 데이터를 전송할 수 있으며, 서버는 이 데이터를 즉시 처리할 수 있습니다.
        
        이러한 방식으로 0-RTT 기법은 3-Way Handshake의 지연을 줄이고, 통신 성능을 향상시킵니다. 하지만 이를 사용할 때에는 보안과 관련된 고려 사항이 있으며, 적절한 보안 메커니즘을 사용하여 데이터의 무결성과 기밀성을 보호해야 합니다.
        
    
- **4-Way Handshake에 대해 설명해 주세요.**
    
    4-Way Handshake는 네트워크 프로토콜에서 연결을 종료하기 위해 사용되는 절차입니다. 특히 TCP에서 연결을 종료할 때 사용됩니다. 4-Way Handshake는 연결을 종료하는 과정 중에 서로간에 FIN (Finish) 패킷을 교환하여 이루어집니다. 이 절차를 통해 양쪽 호스트는 연결 종료에 동의하고, 연결이 안전하게 종료되도록 합니다.
    
    4-Way Handshake의 단계는 다음과 같습니다:
    
    1. **호스트 A가 연결 종료를 요청하는 FIN 패킷을 전송합니다.**
        - 호스트 A는 통신을 종료하고자 할 때 연결 종료를 요청하는 FIN 패킷을 보냅니다.
    2. **호스트 B는 FIN 패킷을 수신하고 확인하기 위한 ACK 패킷을 전송합니다.**
        - 호스트 B는 호스트 A로부터 받은 FIN 패킷을 수신하고, 이를 확인하기 위해 ACK (Acknowledgment) 패킷을 보냅니다.
    3. **호스트 B도 연결 종료를 요청하는 FIN 패킷을 전송합니다.**
        - 호스트 B는 호스트 A에게 연결 종료를 요청하기 위해 자신도 FIN 패킷을 전송합니다.
    4. **호스트 A는 FIN 패킷을 수신하고 확인하기 위한 ACK 패킷을 전송합니다.**
        - 호스트 A는 호스트 B로부터 받은 FIN 패킷을 수신하고, 이를 확인하기 위해 ACK 패킷을 보냅니다.
    
    이러한 과정을 통해 양쪽 호스트는 연결 종료에 동의하고, 안전하게 연결이 종료됩니다. 4-Way Handshake는 양쪽 호스트 간의 상태를 서로 확인하고, 데이터의 손실 없이 연결을 종료하기 위한 중요한 단계입니다.
    
    - 패킷이 4-way handshake 목적인지 어떻게 파악할 수 있을까요?
        1. **패킷의 헤더 정보 확인**: 패킷의 TCP 헤더를 확인하여, SYN, FIN, ACK 등의 플래그가 설정되어 있는지를 확인할 수 있습니다. 4-Way Handshake 과정에서는 각각의 단계에서 해당 플래그가 설정됩니다.
        2. **시퀀스 번호 확인**: 각각의 패킷에는 시퀀스 번호와 확인 번호가 포함되어 있습니다. 4-Way Handshake 과정에서는 각각의 단계에서 시퀀스 번호와 확인 번호가 특정한 패턴을 따르게 됩니다. 이를 확인하여 패킷이 4-Way Handshake의 일부인지를 식별할 수 있습니다.
        3. **타이밍 및 순서 확인**: 4-Way Handshake 과정에서는 각각의 단계가 정해진 순서와 시간에 따라 발생합니다. 따라서 패킷의 타이밍 및 순서를 확인하여 해당 패킷이 4-Way Handshake의 일부인지를 식별할 수 있습니다.
        4. **페이로드 분석**: 패킷의 페이로드를 분석하여 특정 프로토콜 메시지 또는 데이터를 확인할 수 있습니다. 4-Way Handshake 과정에서는 각각의 단계에서 특정한 메시지가 포함되어 있을 수 있으며, 이를 확인하여 해당 패킷이 4-Way Handshake의 일부인지를 식별할 수 있습니다.
        
    - 빨리 끊어야 할 경우엔, (즉, 4-way Handshake를 할 여유가 없다면) 어떻게 종료할 수 있을까요?
        
        4-Way Handshake를 거치지 않고 빠르게 연결을 종료해야 하는 경우에는 TCP의 RST (Reset) 패킷을 사용하여 연결을 강제로 종료할 수 있습니다. RST 패킷은 TCP 연결을 즉시 종료하고 통신 상대방에게 연결이 갑자기 끊어졌음을 알리는 데 사용됩니다.
        
        RST를 사용하여 연결을 종료하는 과정은 다음과 같습니다:
        
        1. **연결을 종료하고자 하는 호스트가 RST 패킷을 생성합니다.**
            - 연결을 종료하고자 하는 호스트는 TCP 헤더에 RST 플래그를 설정한 패킷을 생성합니다.
            - 이때 송신자와 수신자의 IP 주소, 포트 번호 등이 포함됩니다.
        2. **RST 패킷을 상대방에게 전송합니다.**
            - 호스트는 생성한 RST 패킷을 상대방에게 전송합니다.
            - 이때 상대방은 이 패킷을 수신하고 해당 연결이 더 이상 유효하지 않음을 인식합니다.
        3. **상대방은 RST 패킷을 받고 연결을 종료합니다.**
            - 상대방은 RST 패킷을 받으면 해당 연결을 즉시 종료하고, 이후의 데이터 전송을 거부합니다.
            
    - 4-Way Handshake 과정에서 중간에 한쪽 네트워크가 강제로 종료된다면, 반대쪽은 이를 어떻게 인식할 수 있을까요?
        1. **타임아웃 발생**: 한 쪽 호스트가 FIN 패킷을 보내고 일정 시간이 경과한 후에도 연결 종료에 대한 응답이 없으면, 다른 쪽 호스트는 타임아웃이 발생했다고 판단할 수 있습니다. 이를 통해 연결이 강제로 종료되었음을 감지할 수 있습니다.
        2. **RST 패킷 수신**: 한 쪽 호스트가 강제로 종료되면, 상대쪽 호스트는 해당 호스트로부터 RST 패킷을 받을 수 있습니다. RST 패킷은 TCP 연결을 즉시 종료하고 상대쪽 호스트에게 연결이 갑자기 끊어졌음을 알리는 데 사용됩니다. 이를 통해 상대쪽 호스트는 연결이 끊어졌다는 사실을 알 수 있습니다.
        3. **활성 상태 확인**: 연결이 활성화된 상태인 경우, 양쪽 호스트는 일정한 간격으로 Keep-Alive 패킷을 교환합니다. 한 쪽 호스트가 이러한 Keep-Alive 패킷을 수신하지 못하면, 다른 쪽 호스트는 연결이 끊어진 것으로 간주할 수 있습니다.
        
    - 왜 종료 후에 바로 끝나지 않고, TIME_WAIT 상태로 대기하는 것 일까요?
        1. **패킷의 순서화 보장**
            
            : TIME_WAIT 상태에서 대기하는 동안, 이전에 전송되었던 모든 패킷이 도착할 때까지 대기합니다. 이를 통해 패킷의 순서화가 보장되고, 재전송된 패킷이나 오래된 패킷이 도착하여 연결에 영향을 미치는 것을 방지합니다.
            
        2. **패킷의 재전송 및 지연에 대한 대비**
            
            : TIME_WAIT 상태에서 대기함으로써, 연결 종료에 대한 확인 패킷이 재전송되거나 네트워크에서 발생하는 지연에 대비할 수 있습니다. 이는 연결이 완전히 종료된 후에도 잠재적인 패킷 손실이나 지연으로 인한 문제를 방지하는 데 도움이 됩니다.
            
        3. **네트워크 리소스 회수 지연**
            
            : TIME_WAIT 상태에서 대기하는 동안, 해당 연결에 대한 관련된 네트워크 리소스가 완전히 해제되기를 기다립니다. 이는 TCP/IP 스택이 사용한 포트나 리소스를 다른 연결이 재사용하지 못하게 하고, 다른 연결과의 혼선을 방지합니다.
            
        4. **패킷 경로에 대한 안정성**
            
            : TIME_WAIT 상태에서 대기하는 동안, 이전 연결이 사용한 경로가 완전히 안정화될 때까지 대기합니다. 이는 다른 연결에서 발생할 수 있는 패킷 혼란을 방지하고, 안정적인 통신 환경을 유지하는 데 도움이 됩니다.
            
        
        TIME_WAIT 상태에서 대기하는 기간은 보통 두 배의 MSL(Maximum Segment Lifetime)로 설정됩니다. 이는 일반적으로 연결 종료에 대한 패킷이 네트워크에서 사라지는 데 걸리는 최대 시간을 나타냅니다.
