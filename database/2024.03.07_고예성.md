# 면접 대비용

---

- Key (기본키, 후보키, 슈퍼키 등등...) 에 대해 설명해 주세요.
    
    키는 무언가를 식별하는 고유한 식별자(identifier)를 말합니다. 데이터베이스에서 조건에 만족하는 행을 찾거나, 순서를 정렬할 때, 다른 행과 구별할 수 있는 기준이 되는 속성의 집합을 말합니다.
    
    키의 종류에는 슈퍼키(super key), 후보키(candidate key), 기본키(primary key), 대체키(alternate key), 외래키(foreign key)가 있습니다.
    
    ## **슈퍼키(super key)**
    
    테이블에서 각 행을 유일하게 식별할 수 있는 하나 또는 그 이상의 속성들의 집합을 슈퍼키라고 합니다.
    
    슈퍼키는 유일성만 만족하면 됩니다.
    
    유일성이란 하나의 키로 특정 행을 찾아낼 수 있는 고유한 데이터 속성을 말합니다.
    
    ![Untitled](%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8%20%E1%84%83%E1%85%A2%E1%84%87%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%2033c69d4c4ac940b39cd413c6600098d5/Untitled.png)
    
    위의 테이블에서  {FILE_ID}를 통해 1행과 2행을 구분할 수 있습니다.
    
    그 뿐만 아니라 {File_ID, POST_ID} 혹은 {FILE_ID, POST_ID, FILE_NAME}으로도 구분 할 수 있습니다.
    
    위의 속성들의 집한은 두 개의 Row를 유일하게 구분할 수 있습니다.
    
    따라서 위의 Key들은 모두 테이블의 슈퍼키가 됩니다.
    
    하지만 다음과 같은 속성들의 집합 {POST_ID, FILE_NAME, FILE_SIZE_FILE_TYPE}을 생각해봅시다.
    
    이 속성들의 집합을 통해서는 고유한 Row를 구분할 수 없습니다.
    
    왜냐하면 하나의 게시글(POST_ID)에 내용은 다르지만 똑같은 형식의 파일이 두 개 올라갈 수도 있기 때문입니다.
    
    따라서 위의 집합은 슈퍼키가 될 수 없습니다.
    
    ## **후보키(Candidate key)**
    
    후보키는 슈퍼키와 비슷하게 각 행을 유일하게 식별할 수 있는 키를 말합니다.
    
    하지만 다른 점이 있는데, 최소한의 속성들의 집합이란 점입니다.
    
    띠라서 후보키는 유일성과 최소성을 모두 만족해야 합니다.
    
    그리고 이러한 속성들을 통해 기본키가 될 수 있는 키들의 집합입니다.
    
    기본키에 관해서는 나중에 더 자세히 알아보고 지금은 후보키에 집중해봅시다.
    
    ![Untitled](%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8%20%E1%84%83%E1%85%A2%E1%84%87%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%2033c69d4c4ac940b39cd413c6600098d5/Untitled.png)
    
    위에서 봤던 파일에 관한 테이블입니다. 
    
    이 테이블의 속성들을 최소한으로 가지면서 각 Row를 유일하게 식별하려면 어떻게 키를 만들어야 할까요?
    
    여기서 {FILE_ID} 속성은 각각의 파일들이 고유하게 가지고 있는 번호입니다.
    
    그리고 딱 하나의 속성만 가지고 있기 때문에 {FILE_ID}는 후보키가 됩니다.
    
    이 테이블에서 {FILE_ID}를 제외하면 후보키가 없네요.
    
     
    
    ## **기본키(Primary key)**
    
    기본키는 후보키들 중의 하나로 최소성과 유일성을 만족합니다.
    
    테이블에서 기본키는 오직 1개만 지정할 수 있습니다.
    
    기본키는 NULL 값을 가질 수 없고 중복된 값을 가질 수 없습니다.
    
    이는 당연합니다. 기본키는 유일성과 최소성을 만족하는 여러 후보키들 중에 하나를 선택하기 때문입니다.
    
    ![Untitled](%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8%20%E1%84%83%E1%85%A2%E1%84%87%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%2033c69d4c4ac940b39cd413c6600098d5/Untitled.png)
    
    위의 테이블에서 후보키는 {FILE_ID} 밖에 없었습니다.
    
    기본키는 후보키들 중에 하나로 선택해야 하는데 후보키가 하나이므로 {FILE_ID}는 기본키입니다.
    
    데이터베이스에는 이러한 기본키가 중복되지 않도록 만드는 속성(ex. MySQL의 AUTO_INCREMENT)이 있어
    
    이를 활용하면 특별한 설정 없이 각 레코드 마다 자동으로 고유한 값을 가지도록 할 수 있습니다.
    
    ## 대체키(Alternate key)
    
    후보키는 여러 개 존재할 수 있습니다. 그 중에 하나를 기본키로 지정하게 되면 남은 후보키들은 대체키가 됩니다.
    
    간단하게 정리하면, 대체키는 기본키로 선정되지 않은 후보키입니다.
    
    ## 외래키(Foreign key)
    
    RDB에서 하나의 테이블은 다른 테이블과 관계를 맺어 데이터를 참조할 수 있습니다.
    
    테이블 간의 관계를 맺기 위해서는 하나의 테이블이 다른 테이블의 속성을 갖고 있어야 합니다.
    
    테이블과 테이블 간에 관계를 맺는 연산을 Join이라 합니다.
    
    그리고 Join을 하기 위해 사용되는 다른 테이블의 속성을 외래키라고 합니다.
    
     
    
    예를들어 POSTS라는 테이블이 있고 이 테이블은 POST_ID라는 속성을 가지고 있습니다.
    
    ![Untitled](%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8%20%E1%84%83%E1%85%A2%E1%84%87%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%2033c69d4c4ac940b39cd413c6600098d5/Untitled%201.png)
    
    ![Untitled](%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8%20%E1%84%83%E1%85%A2%E1%84%87%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%2033c69d4c4ac940b39cd413c6600098d5/Untitled.png)
    
    POST_ID가 1인 게시글에 관한 데이터를 찾는 동시에 첨부된 파일들을 모두 조회하고 싶습니다.
    
    그러면 게시글 테이블과 파일 테이블을 동시에 놓고 파일 테이블에서 POST_ID가 1인 Row들을
    
    POST_ID가 1인 POSTS와 연관시켜야겠죠?
    
    근데 만약에 파일 테이블에 POST_ID가 없다면 어떨까요?
    
    어떤 파일이 어떤 POST와 ‘연결’되어 있는지 확인할 수 없습니다.
    
    파일 테이블은 POSTS 테이블과 연관되기 위해 POSTS 테이블이 가진 키를 테이블에 갖게 됩니다.
    
    이를 외래키라고 합니다.
    
    파일 테이블에서 POST_ID가 POSTS 테이블을 참조하는 외래키로 설정했습니다.
    
    만약 파일 테이블에서 임의로 POSTS 테이블에 존재하지 않는 ID를 
    
    POST_ID로 가지려 한다면 어떻게 될까요?
    
    없는 데이터를 참조하기 때문에 오류가 발생할 것입니다.
    
    즉, 데이터의 무결성에 문제가 생깁니다. 
    
    이를 참조 무결성(Referential integrity)이라고 합니다.
    
    데이터베이스는 참조 무결성을 지키기 위해 외래키에 존재하지 않는 데이터를 설정할 수 없습니다.
    
    또한 테이블에 참조되는 데이터보다 참조하는 데이터가 먼저 생길 수 없습니다.
    
    예를 들어 POSTS에 POST_ID 5가 기록되는 것보다 먼저 파일 테이블에 데이터들이 기록될 수 없습니다.
    
    그와 반대로 테이블에서 데이터가 삭제될 때는 파일 테이블에 있는 데이터들이 먼저 삭제된 후
    
    POSTS 테이블에 있는 데이터가 삭제되어야 합니다.
    
    만일 POSTS 테이블에 있는 데이터가 먼저 삭제된다면,
    
    파일 테이블에 있는 데이터들은 참조 무결성을 위배하기 때문에, 문제가 됩니다.
    
    그리고 데이터베이스에서는 시스템 규칙으로 이러한 행위를 막습니다.
    
    ## 유니크 키(Unique key)
    
    유니크 키는 영어 뜻 그대로 독특한, 유일한 키입니다.
    
    이 또한 유일성을 가지기 위해 설정하는 키이고 테이블에 있는 데이터를 유일하게 식별합니다.
    
    유일하게 식별해야 하기 때문에 무결성이 제약 조건 중 하나이고 null 값을 허용하지 않습니다.
    
    여기서 기본키와 유니크 키를 헷갈릴 수 있습니다.
    
    둘 다 Row를 고유하게 식별하려고 유일성과 최소성을 만족하는 키인데, 어떤 점이 다를까요?
    
    기본키는 ‘테이블의 식별자’ 역할을 합니다.  
    
    그래서 테이블에서 딱 하나의 집합에만 지정할 수 있습니다.
    
    반면 유니크 키는 유일성을 가지는 키의 집합에 모두 설정할 수 있습니다.
    
    집합에서 데이터가 중복되는 것을 제어하는 역할을 합니다.
    
    예를 들어, 회원 이름을 유니크 키로 지정한다면, 이 데이터는 중복될 수 없습니다.
    
    회원 이름뿐만 아니라 휴대폰 번호를 유니크 키로 지정하면 휴대폰 번호는 중복될 수 없습니다.
    
    유니크 키는 기본키와 달리 각 컬럼마다 지정이 가능합니다.
    
- 기본키는 수정이 가능한가요?
    
    외래키와 연관관계가 없는 기본키는 수정이 가능합니다. 하지만 외래키로 연관관계가 있는 부모 행의 기본키는 변경이나 삭제가 불가능합니다. 이는 외래키 제약 조건에 위배되기 때문입니다.
    
    또한 외래키의 경우에 수정이 가능하지만, 부모 테이블에 없는 데이터로는 수정이 불가능합니다. 이 또한 외래키 제약조건에 의해서 입니다. 
    
    하지만 외래키로 연관관계가 걸린 기본키가 있는 테이블에 update-cascade와 같은 설정을 걸어 놓으면 기본키가 변경될 때 외래키를 함께 변경하여 외래키 제약조건에 위배되지 않게 만들어주어서 가능합니다.
    
    [https://mangchhe.github.io/db/2022/01/22/PrimaryForeignKeyUpdate/](https://mangchhe.github.io/db/2022/01/22/PrimaryForeignKeyUpdate/)
    
    **Primary Key**
    
    :**기본키** 중복을 허용하지 않는다. NULL을 허용하지 않는다. 예시) ID, 주민번호
    
    **Unique Key**
    
    :**고유키** 중복을 허용하지 않는다. NULL을 허용한다. 예시) e-mail
    
    **Foreign Key**
    
    :**외래키** JOIN(테이블과 테이블의 연결)이 목적. NULL을 허용한다. 외래키로 지정된 컬럼은 연결된 테이블에서 PK나 UK로 설정되어 있어야 한다.
    
    **CHECK**
    
    : 범위를 지정. 지정된 값 외에 사용할 수 없다. 중복을 허용한다. NULL을 허용한다.
    
    **NOT NULL**
    
    : 중복을 허용한다. NULL을 허용하지 않는다.
    
- 사실 MySQL의 경우, 기본키를 설정하지 않아도 테이블이 만들어집니다. 어떻게 이게 가능한 걸까요?
    
    이는 MySQL에서 기본키를 강제하는 것이 아니라 선택사항 취급하기 때문입니다. 즉, 데이터베이스 설계자가 기본키를 명시적으로 지정하지 않아도 MySQL은 자동으로 기본키를 생성하지 않고 대신 모든 필드를 포함하는 인덱스를 생성합니다.
    
    IInnoDB 스토리지 엔진을 사용하는 경우에는 테이블에 대한 기본 클러스터드 인덱스를 만듭니다. 이는 테이블이 물리적으로 정렬된 순서로 데이터를 저장하는데 사용되며, 이 인덱스는 테이블의 기본키가 아닌 경우에도 생성됩니다. 이 인덱스를 통해 레코드를 빠르게 찾을 수 있습니다.
    
    하지만 데이터베이스 설계 및 성능 향상을 위해 기본키를 명시적으로 정의하는 것이 일반적으로 권장됩니다. 기본키를 명시적으로 정의하면 데이터 무결성이 보장되고 테이블 간의 관계를 설정하거나 인덱스를 효율적으로 사용하는데 도움이 됩니다. 이를 통해 정확성과 성능을 높일 수 있습니다.
    
- 외래키 값은 NULL이 들어올 수 있나요?
    
    외래키 제약조건에 따라 NULL이 허용되지 않을 수 있지만 이는 데이터베이스 시스템에 따라 다릅니다.
    
    MySQL의 경우 외래키에 NULL을 허용하는 것이 기본적으로 활성화되어 있습니다.
    
    이는 외래키 값이 부모 테이블의 기본키와 일치하지 않아도 NULL 값을 허용하도록 하는 기본설정입니다.
    
    외래키에 NULL을 허용하는 경우 외래키가 부모 테이블의 기본키와 일치하지 않는 경우에도 자식 테이블에 데이터를 삽입 할 수 있습니다. 이러한 유연성은 데이터베이스 설계 및 데이터 관리를 단순화할 수 있기 때문입니다. 하지만 외래키에 NULL을 허용하지 않도록 설정하여 무결성을 강화하고 정합성을 유지할 수 있습니다.
    
- 어떤 칼럼의 정의에 UNIQUE 키워드가 붙는다고 가정해 봅시다. 이 칼럼을 활용한 쿼리의 성능은 그렇지 않은 것과 비교해서 어떻게 다를까요?
    
    일반적으로 unique 키워드가 붙은 컬럼은 값이 중복되지 않는 것을 보장합니다. 
    
    하지만 경우에 따라 unique 키워드가 있는 경우와 없는 경우의 쿼리 성능차이가 있습니다.
    
    1. 검색 쿼리
        
        만일 컬럼에 unique 키워드가 있다면 해당 컬럼은 인덱스가 자동으로 생성됩니다. 이는 검색 쿼리가 해당 컬럼을 사용할 때 더 빠른 검색을 가능하게 합니다. 그래서 인덱스를 통해 중복 없이 고유한 값을 빠르게 찾을 수 있습니다. 만일 unique 키워드가 없는 경우 인덱스가 생성되지 않아 검색 시 테이블 전체를 스캔해야 합니다. 그래서 더 많은 시간과 자원이 소요될 수 있습니다.
        
    2. 삽입/수정 쿼리
        
        unique키워드가 있는 컬럼에 데이터를 삽입 또는 수정을 시도할 때 해당 컬럼의 값을 먼저 검사하여 중복 여부를 확인합니다. 중복된 값이 있을 경우 삽입 또는 수정이 거부되고 이는 더 오랜 시간이 걸리게 합니다. 반면 unique 키워드가 없을 때는 중복 여부를 확인할 필요가 없어서 데이터의 삽입 및 수정 작업이 더 빨리 수행될 수 있습니다.
        
        또한 삽입 및 수정 시간이 증가하는 원인은 인덱스 트리에도 있습니다.
        
        데이터베이스에서 사용되는 B-트리는 데이터를 효율적으로 저장하고 검색하기 위해 사용됩니다.
        
        B트리는 아래와 같은 특성을 가지고 있습니다.
        
        1. 균형 트리 구조 : B-트리는 모든 리프 노드가 같은 레벨에 있는 균형 트리 구조를 가지고 있습니다. 이는 검색에 있어서 일정한 성능을 보장합니다.(시간복잡도가 O(N)인 skewed tree가 만들어지는 것을 방지)
        2. 노드의 다차원성 : B-트리의 각 노드는 여러 개의 키를 가질 수 있습니다. 이는 한 노드에서 여러 값을 관리할 수 있도록 합니다.
        3. 자식 노드의 수: B-트리의 노드는 여러 자식을 가질 수 있습니다. 이는 더 많은 키를 저장하고 더 넓은 범우이의 값을 효율적으로 관리할 수 있도록 합니다.
        
        Unique 키워드를 사용하여 삽입, 수정, 삭제를 하기 전에 먼저 해당 칼럼의 값을 검사하여 중복 여부를 확인합니다. 이 과정에서 B-트리를 사용하여 해당 값이 이미 존재하는지 확인(O(logN))해야 합니다. 중복된 값이 발견된 경우 삽입, 삭제, 수정이 거부됩니다. 만일 중복된 값이 없다면 새로운 값이 삽입, 수정, 삭제될 때 트리의 균형을 유지하기 위해 재조정이 필요합니다. 
        
        만일 삽입으로 인해 노드의 크기가 초과되면 분할 작업이 수행됩니다.
        
        삭제로 인해 노드의 크기가 작아지면 병합(merge)작업이 수행됩니다.
        
        수정은 삭제와 삽입을 결합한 방식으로 먼저 수정할 값을 삭제한 후 트리를 재조정한 후 삽입을 한 후 트리를 재조정합니다.
        
        B-트리에서 수행시간이 증가하는 이유는 주로 트리의 탐색과 리밸런싱 작업 때문입니다.
        
    

---

- RDB와 NoSQL의 차이에 대해 설명해 주세요**.** RDB의 어떠한 특징 때문에 NoSQL에 비해 부하가 많이 걸릴 "수" 있을까요? (주의: 무조건 NoSQL이 RDB 보다 빠르다라고 생각하면 큰일 납니다!)
    
    
    1. RBD는 새로운 데이터에 관한 정보를 넣고 싶을 경우 컬럼을 추가하기 위해 스키마를 변경해야한다. 만약 그 테이블에 이미 많은 데이터가 있을 경우 새로운 컬럼이 추가될 경우 대량에 데이터에 관해 쓰기 작업을 해야하기 때문이다. 이러한 대량의 쓰기작업은 부담스러운 작업이고 이로 인해 백엔드 애플리케이션과 사용자에게 안좋은 영향을 줄 수 있다. 즉, RDB는 테이블 구조로 인해 유연한 확장성이 부족한 것이다.
    2. RDB는 데이터 중복 제거를 위해 정규화를 진행하여 설계한다. 이를 통해 데이터가 중복되는 것을 최소화할 수 있는 장점이 있지만 연관된 데이터를 읽기 위해서는 많은 Join을 해야하는 문제가 발생한다. Join은 DBMS에 있어 부담스러운 작업이다. 이로 인해 작업시간이 늘어나면서 응답시간도 늘어난다. 복잡한 join은 읽기 성능의 하락이 생긴다.
    3. RDB는 기본적으로 한 대의 컴퓨터에 저장된다. 만일 이 RDB 서버에 읽기/쓰기 작업(부하)이 늘어날 경우 처리하는게 힘들어진다. 이럴 때 RDB는 Scale up을 통한 DB성능을 향상시킨다. 물론 이렇게 스케일 업뿐만 아니라 레플리케이션(복제)을 이용해 똑같은 데이터베이스를 복사하여 읽기 전용 모델과 쓰기 모델로 나누어 부하를 분산시킬 수 있다. 하지만 write 트래픽이 많아진다면, 결국 부하를 크게 받게 된다. 물론 RDB에서 이러한 문제를 해결하기 위해 샤딩, 멀티-마스터 형태를 취해서 해결할 수 있다. 하지만 이러한 방식(스케일 아웃)은 RDB가 유연하게 취할 수 있는 방식이 아니다. 스케일 아웃, 샤딩을 할 경우 데이터 동기화 과정(데이터 복제/옮김)이 필요하기 때문이다.
    4. RDB는 트랜잭션의 ACID를 보장하려다 보니 DB 서버의 성능(Throughput, Latency)에 영향을 미친다.
    
- NoSQL의 강점과, 약점이 무엇인가요?
    
    인터넷이 급속도로 보급되게 되면서 많은 사용자가 등장했고 이에 따라 높은 throughput, 낮은 latency가 요구되었다. 또한 다양한 사용자들이 다양한 형태의 데이터를 발생시켜 비정형 데이터가 증가하게 되었다. 그래서 위와 같은 RDB의 단점을 보완하고자 NoSQL이 등장하게 되었다.
    
    NoSQL은 Not Only SQL이란 의미로 SQL도 커버하지만, RDB가 커버하지 못한 것을 커버하겠다는 의미이다.
    
    1. flexible schema : 스키마 자체가 유연성이 있다.
        
        예를들어 몽고디비의 컬렉션은 그저 이름만 정해주고 데이터가 들어가는 형태를 미리 정해주지 않아도 된다. 다만 데이터를 넣을 때 정의해주면 된다. (참고로 몽고디비는 JSON 형태로 데이터를 넣어준다.) 또한 특정 데이터를 읽고 싶을 때는 데이터의 조건을 가지고 찾기만 하면 된다.  그리고 컬렉션의 모든 도큐먼트를 조회하고 싶다면 아무 정의 없이 조회하면 된다.
        
        스키마가 유연성이 있기 때문에 도큐먼트를 정해진 형식 없이 저장할 수 있다.
        
        하지만 단점으로 애플리케이션 레벨에서 스키마를 관리해야 한다.
        
        몽고디비가 MySQL처럼 들어가는 데이터를 관리해주는게 아니라 개발자가 관리해야하는 것이다.
        
    2. 데이터의 중복을 허용 : Join을 회피합니다.
        
        예를 들어 몽고디비에서 주문 정보를 담고있는 컬렉션에서 모든 도큐먼트를 읽어왔다고 하자. 여기서 같은 사용자가 주문한 두 상품에 관한 정보가 있는데, 사용자의 이름과 휴대폰 번호가 중복된 채로 저장되어있다. RDB라면 이러한 중복데이터를 피하기 위해 다른 테이블로 저장하겠지만 NoSQL은 Join을 피하기 위해 중복을 허용한다. 즉 Join에 필요한 비용을 줄일 수 있는 것이다. 하지만 중복 데이터를 애플리케이션 레에벨에서 최신 데이터를 유지할 수 있도록 관리해야 한다.
        
    3. 스케일 아웃에 최적화된 DB
        
        RDB에 비해 스케일 아웃하기 좋은 형태이기 때문에, 서버 여러 대로 하나의 클러스터를 구성하여 사용한다. 이때 클러스터는 방식은 마치 RDB 테이블을 파티셔닝하는 것처럼 구성한다. 특정 데이터는 특정 DB에 저장되고 읽어오도록 만드는 것이다. 이것이 가능한 이유는 데이터의 중복을 허용하기 때문이다.
        
    4. NoSQL은 트랜잭션의 특성(ACID)의 일부를 포기하고 high-throughput, low-latency를 추구한다.
        
        하지만 금융시스템, 예약시스템 처럼 데이터 일관성(Consistency)가 중요한 환경에서는 NoSQL이 조심스럽다.
        
    
    SQL 데이터베이스 사용이 더 좋을 때
    
    - 변경될 여지가 없는 명확한 스키마가 사용자와 데이터에게 중요한 경우
    - 관계를 맺고 있는 데이터가 자주 변경되는 애플리케이션(데이터 업데이트가 잦은 시스템)
    - 데이터베이스의 ACID 성질을 준수해야 하는 경우(금융서비스)
    
    NoSQL 데이터베이스 사용이 더 좋을 때
    
    - 정확한 데이터 구조를 알 수 없거나 변경/확장 될 수 있는 경우
    - 읽기를 자주 하지만, 데이터 변경은 자주 없는 경우
    - 데이터베이스를 수평으로 확장해야하는 경우(막대한 양의 데이터)
    - 데이터 정합성이나 일관성이 최고 우선순위가 아닌 경우
    
- NoSQL을 활용한 경험이 있나요? 있다면, 왜 RDB를 선택하지 않고 해당 DB를 선택했는지 설명해 주세요
    
    인메모리 데이터베이스인 레디스를 사용했습니다. 회원가입 서비스에서 회원 인증을 위해 이메일로 랜덤 인증번호를 발송하고 3분 이내에 인증해야만 하는 비즈니스 로직이었습니다. 스케일 아웃을 고려하지 않은 모노리스 서버였다면 세션을 이용하여 임시 발급된 인증번호를 인증하도록 만들 수 있겠지만, 서버가 스케일 아웃할 경우에는 유저의 요청이 어떤 서버로 갈지 모르기 때문에 세션을 이용할 수 없었습니다. 그렇다고 RDB에 저장하기에는 보관할 필요 없는 데이터이고 머무는 시간이 짧습니다. 오히려 RDB에 데이터를 삽입했다가 삭제하는데 자원이 더 들어갈 거라 생각했습니다. 따라서 분산환경과 캐싱에 적절한 DBMS가 필요했고 레디스가 이에 알맞았습니다. 레디스는 스키마를 만들 필요 없이 key-value 형태로 작동하여 간단하고, 인메모리 데이터베이스이기 때문에 데이터를 삽입/삭제하는데 들어가는 자원이 RDB에 비해 상대적으로 적고, 장애가 나서 손실되더라도 괜찮은 데이터를 저장하기에 좋습니다. 또한 스케일 아웃을 해도 분산환경이기 때문에 괜찮을 뿐만 아니라 인증하지 않으면 레디스가 3분 후에 데이터를 자동으로 삭제할수 있기 때문에(TTL) 모든 요구사항을 만족시켰습니다.
    
- RDBMS, NoSQL에서의 클러스터링/레플리케이션 방식에 대해 설명해 주세요.
    
    
    리플리케이션은 여러 개의 DB를 수직적인 구조(Master-Slave)로 구축하는 방식으로 리플리케이션에서 Master Node는 쓰기 작업만을 처리하며 Slave Node는 읽기 작업만을 처리한다. 리플리케이션은 비동기 방식으로 노드들 간의 데이터를 동기화 한다.
    
    - 읽기 작업이 많은 DB요청에서는 replication만으로 충분히 성능 높이기가 가능하다. 비동기 방식이라 지연시간이 거의 없다.
    - Master 노드가 다운되면 복구/대처가 까다롭다. 동기화가 보장되지 않아 일관성 있는 데이터 신뢰가 불가능하다.
    
    여러 개의 DB를 권한에 따라 수직 구조로 구축하는 방식
    
    데이터베이스 서버와 스토리지를 모두 확장
    
    Master Node는 쓰기 작업만, Slave Node는 읽기 작업만(기존의 부하를 분산)
    
    비동기 방식으로 노드 데이터 동기화
    
    ![스크린샷 2024-03-07 오전 10.37.15.png](%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8%20%E1%84%83%E1%85%A2%E1%84%87%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%2033c69d4c4ac940b39cd413c6600098d5/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.37.15.png)
    
    클러스터링은 여러 개의 DB를 수평적인 구조로 구축하는 방식으로 분산환경을 구성하여 Single Point Of Failure와 같은 문제를 해결할 수 있는 Fail Over 시스템을 구축하기 위해서 사용된다.
    
    - 노드들 간의 데이터를 동기화해 일관성 있는 데이터를 신뢰할 수 있다. 1개 노드가 죽어도 다른 노드가 살아있어 시스템을 장애없이 운영할 수 있다.
    - replication에 비해 쓰기 성능이 떨어지고 장애가 전파된 경우 처리가 까다롭다.
    
    여러 개의 DB를 수평 구조로 구축하는 방식.(데이터베이스 서버 확장)
    
    Fail Over 시스템을 구축하기 위해 사용.
    
    데이터베이스가 동작하지 않으면 전체 서비스가 동작할 수 없다는 점을 해결하기 위해 Clustering을 통해 데이터베이스 서버를 늘린다.
    
    동기 방식으로 노드들 간의 데이터 동기화
    
    ![스크린샷 2024-03-07 오전 10.38.59.png](%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8%20%E1%84%83%E1%85%A2%E1%84%87%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%2033c69d4c4ac940b39cd413c6600098d5/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-03-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.38.59.png)
    
    ### **RDBMS에서의 클러스터링과 레플리케이션:**
    
    1. **클러스터링(Clustering)**:
        - RDBMS에서의 클러스터링은 주로 공유 디스크 아키텍처를 기반으로 한다. 이는 여러 대의 서버(노드)가 공유된 스토리지에 접근할 수 있도록 하는 것을 의미한다.
        - 주로 고가용성과 내결함성을 제공하기 위해 사용되는 방식이다. 한 노드에 장애가 발생하더라도 다른 노드가 작업을 계속할 수 있다.
        - 여러 노드 간에 데이터를 동기화하고 트랜잭션을 처리하는 복잡한 장애 탐지 및 처리 기능을 제공
    2. **레플리케이션(Replication)**:
        - RDBMS에서의 레플리케이션은 주 서버에서 변경된 데이터를 여러 대의 보조 서버로 복제하는 과정을 말한다.
        - 일반적으로 동기식 또는 비동기식으로 이루어집니다. 동기식 레플리케이션은 주 서버의 트랜잭션이 완료될 때까지 대기하고, 비동기식 레플리케이션은 데이터 변경을 지연시키지 않고 즉시 복제한다.
        - 읽기 성능을 향상시키고, 고가용성을 제공하며, 장애 발생 시에도 데이터의 손실을 방지한다.
    
    ### **NoSQL에서의 클러스터링과 레플리케이션:**
    
    1. **클러스터링(Clustering)**:
        - NoSQL에서의 클러스터링은 주로 수평 확장을 위해 사용된다. 즉, 데이터베이스에 더 많은 노드를 추가하여 처리 능력을 증가시킨다.
        - 데이터를 여러 노드에 분산시키기 위해 파티셔닝을 사용한다. 데이터는 해시 파티셔닝, 범위 파티셔닝 등의 방식으로 여러 노드에 분산된다.
    2. **레플리케이션(Replication)**:
        - NoSQL에서의 레플리케이션은 주로 비동기식으로 이루어진다. 변경된 데이터는 주 서버에서 보조 서버로 비동기적으로 복제된다.
        - 읽기 작업의 성능을 향상시키고, 고가용성을 제공. 장애 발생 시에도 보조 서버로 서비스를 이전할 수 있다.
    
- 이러한 분산 환경에선, 트랜잭션을 어떻게 관리할 수 있을까요?
    
    **Two Phase Commit**
    
    - 2단계를 거쳐 커밋이나 롤백을 진행하는 과정
    - 트랜재션을 조율하는 coodinator (조정자) 존재
    - 1단계 : Prepare → 데이터를 저장할 수 있는 상태인지 확인
    - 2단계 : Commit
    - 이 과정 중 한 대의 DB라도 Commit할 수 없다면, 모두 Rollback
    
    → NoSQL은 제공하지 않는 문제가 있음
    
    → 서비스가 많아질 경우 응답 시간이 지연된다.
    
    → Coodinator가 단일 장애 지점.
    
    [https://waspro.tistory.com/734](https://waspro.tistory.com/734)
    
    **Saga 패턴**
    
    - 트랜잭션 관리 주체를 DBMS가 아닌 Application로 변경
    - App 하위에 있는 DB는 로컬 트랜잭션만 관리
    - 연속적인 트랜잭션에 대한 실패 처리를 어플리케이션에서 구현해야 한다
    - 격리성을 보장해 주지 않지만, 최종 일관성을 보장해준다
    
    - **Choreography-Based Saga**
        - 로컬 트랜잭션을 관리하고, 완료 시 완료 이벤트를 처리하고, 다음 어플리케이션에서 완료 이벤트를 수신하기 전까지 대기한다.
        - 그 후 다음 작업 실행.
        - 구축하기 쉬우나, 트랜잭션 상태를 알기 어려움.
    - **Orchestration-Based Saga**
        - 트랜잭션 처리를 위한 별개의 Saga 인스턴스가 존재.
        - 완료 및 실패 여부를 매니저 인스턴스에 수신하고, 모두 완료되면 인스턴스를 종료하며 작업 종료.
    
    [https://velog.io/@hgs-study/saga-1](https://velog.io/@hgs-study/saga-1)
    
    [https://velog.io/@youngerjesus/마이크로서비스-패턴-분산-트랜잭션-처리](https://velog.io/@youngerjesus/%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C%EC%84%9C%EB%B9%84%EC%8A%A4-%ED%8C%A8%ED%84%B4-%EB%B6%84%EC%82%B0-%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%98-%EC%B2%98%EB%A6%AC)
    
    [https://velog.io/@manx/Replication-Clustering](https://velog.io/@manx/Replication-Clustering)
    
- 마스터, 슬레이브 데이터 동기화 전까지의 데이터 정합성을 지키는 방법은 무엇이 있을까요?
    
    ### Master / Slave Data 동기화 전 까지 데이터 정합성을 지키는 방법
    
    다중 스레드로 쓰기 작업을 수행하는 Master 와 단일 스레드로 쓰기 작업을 수행하는 Slave 간의 속도차에 의해 병목이 발생하게된다.
    
    리플리케이션 과정 중 이러한 병목 현상을 `복제 지연`이라고 한다.
    
    **반동기 복제방식 (Semi-Sync Replication)**
    
    - MySQL 5.5 부터 도입
    - 최소 1대 이상의 복제에 필요한 릴레이 로그 동기화를 보장한다.
    - AFTER_SYNC 모드 방식으로 마스터 엔진에 커밋되기 전에 Slave 릴레이로그 저장을 기다린다.
    - 모든 Slave를 기다리는 것이 아닌 Slave 중 단 1대만이라도 릴레이로그를 수신했다면 Master는 트랜잭션을 완료한다.
    - 최소한의 데이터 정합성을 확보하고 Slave DB의 지연이 트랜잭션 지연으로 이어지지 않게 된다.
    
    **MHA ( Master High Availability )**
    
    - Master DB의 고가용성을 위해 개발된 오픈소스
    - Master 헬스 체크를 주기적으로 수행하던 Slave에서 자동으로 가장 최신 상태의 Slave DB를 Master로 승격시켜 Fail-Over 하는 것
    
    **Semi-Sync Replication + MHA**
    
    - 단 한대라도 릴레이 로그를 수신했고, 릴레이 로그 복구 과정을 통해 동기화하기 때문에 데이터 유실가능성을 낮출 수 있다.
    
    [https://velog.io/@manx/Replication-Clustering](https://velog.io/@manx/Replication-Clustering)
    
    [https://da-nyee.github.io/posts/db-replication-data-consistency-issue/](https://da-nyee.github.io/posts/db-replication-data-consistency-issue/)
    
- 다중 트랜잭션 상황에서의 Deadlock 상황과, 이를 해결하기 위한 방법에 대해 설명해 주세요.
    
    # **데이터베이스에서 데드락(Deadlock) 이란?**
    
    두 개 이상의 트랜잭션들이 동시에 진행될때 서로가 서로에 대한 락을 소유한 상태로 대기 상태로 빠져서 더이상 진행하지 못하는 상황을 데드락(deadlock)이라고 한다.
    
    - 데드락은 트랜잭션을 지원하는 데이터베이스에서는 자주 발생하는 문제이다.
    - 멀티 스레드(Multi-threaded) 어플리케이션에서 발생하는 데드락은 해당 어플리케이션을 완전히 멈추게 해버리기 때문에 위험하다.
    - 하지만 일반적인 DBMS (Database Management System)에서는 데드락 탐지(Deadlock detection) 기능을 제공하기때문에 데드락이 발견되면 자동으로 해소시켜준다 (실제 데드락 상황이 아닐지라도 락에 대한 대기시간이 설정된 시간을 초과하면 이것도 데드락으로 처리된다)
    - 이 과정에서 작업중이던 트랜잭션들 중 일부가 취소되는 경우가 발생 할 수 있기때문에 어플리케이션 레벨에서 해당 트랜잭션을 재실행 하여 작업을 완수할 수 있도록 구성해야한다.
    
    ### **데드락(Deadlock)을 줄일 수 있는 방법**
    
    - 트랜잭션(transaction)을 최대한 간결하게 만든다.
    - 인덱스를 잘 구성해야한다. 더 적게 레코드를 스캔할 수록 더 적은 락이 걸린다.
    - Locking read (`SELECT ... FOR UPDATE`, `SELECT ... LOCK IN SHARE MODE`)를 사용시에 READ_COMMITTED와 같은 더 낮은레벨의 트랜잭션을 사용할 수 있는 상황이라면 적극적으로 사용한다.
    - 트랜잭션 안에서 여러 데이터를 수정할때는 발생하는 Lock의 순서를 항상 순차적으로 만든다.
        - 즉 A, B, C 테이블을 수정시 각각의 트랜잭션에서 A -> B -> C 순서로 수정하면 데드락의 위험이 적다.
        - 예시) 어플리케이션 상의 특정 조건에따라 A -> C -> B 또는 C - B -> A 와 같이 각각 트랜잭션이 동시 실행되면서 다른순서로 데이터를 수정하게 된다면 데드락의 확률이 높아진다.
            - 일반적으로는 row 단위로 lock이 걸리지만 이해를 쉽게 하기 위해 테이블 단위 락을 가정
            - 첫번째 트랜잭션에서 A 테이블 락을 잡음
            - 두번째 트랜잭션에서 C 테이블 락을 잡음
            - 첫번째 트랙잭션에서 C 를 수정하려 하지만 두번째 트랜잭션에서 C 테이블 락을 먼저 잡았기때문에 대기 상태에 빠짐
            - 두번째 트랜잭션이 B 테이블 락을 잡고 수정 후, A 테이블 락을 잡으려 하지만 첫번쨰 트랜잭션이 락을 잡고있기떄문에 대기상태에 빠짐
            - 트랜잭션이 서로 물고물린 상태로 대기상태에 빠짐 (= 데드락)
    - 하나의 구문에 여러 ROW가 포함되는 Batch `INSERT ... ON DUPLICATE KEY UPDATE`를 주의하라. 하나의 Batch 구문은 트랜잭션이 걸린 여러개의 구문 처럼 동작하기때문에 각각의 배치 Query에 포함된 데이터의 PK가 겹치게되면 데드락이 발생할 확률이 있다.
        - 예시) 아래 Deadlock Case 1 참고
    - 트랜잭션들을 완전히 Serialize 한다
        - 예시)
            - 1줄의 데이터만 갖고있는 세마포어용 테이블을 생성
            - 각각의 트랜잭션들이 다른 테이블에 접근하기 전에 먼저 세마포어용 테이블을 업데이트하도록 한다.
            - 세마포어 테이블에 늦게 접근한 트랜잭션은 대기상태에 빠지기 때문에 각 트랜잭션들의 완전한 순차 실행이 보장된다.
    
    ### 데드락 발생 트래킹
    
    데드락을 발생 원인을 한번에 추적하기는 쉽지 않다. 상태를 보여주는 SQL문을 실행하면 `latest detection deadlock` 부분이 존재하여 최근에 데드락이 발생한 쿼리를 확인 가능하다.
    
    ```sql
    SHOW ENGINE INNODB STATUS
    ```
    
    # **데드락 케이스 분석**
    
    ### **Deadlock Case 1**
    
    Upsert 동작(기존 데이터가 존재하면 UPDATE, 없으면 INSERT)의 경우 MySQL에서는 INSERT INTO ... ON DUPLICATE KEY UPDATE 구문을 이용하여 DB차원에서 쿼리로 구현이 가능하기 때문에 매우 편리하다. 하지만 이 여러개의 Row에 대해서 한번에 Batch성으로 실행하게되면 데드락이 발생할 위험이 큰 편이다.
    
    Query A:
    
    ```
     INSERT INTO my_table (pk, name) VALUES(1, 'a'), (2,'b') ON DUPLICATE KEY UPDATE name=VALUES(name);
    
    ```
    
    Query B:
    
    ```
     INSERT INTO my_table (pk, name) VALUES(2, 'a'), (1,'b') ON DUPLICATE KEY UPDATE name=VALUES(name);
    
    ```
    
    위의 두 쿼리가 DB상에서 다른 connection을 통해 들어와서 동시에 실행되면 각각의 쿼리는 2번의 INSERT를 트랜잭션으로 묶어놓은것 처럼 동작한다. 따라서 운이나쁘게 다음과 같은 순서로 실행되면 데드락이 발생한다.
    
    - A에서 pk=1인 row upsert pk=1 lock 획득
    - B에서 pk=2인 row upsert pk=2 lock 획득
    - A에서 pk=2인 row upsert 시도 -> B에서 먼저 lock을 가져갔기때문에 대기
    - B에서 pk=1인 row upsert 시도 -> A에서 먼저 lock을 가져갔기때문에 대기
    - 데드락 발생
    
    Upsert가 아닌 WHERE 조건에의해 여러 row들을 한번에 UPDATE 한다면 비슷한 이유로 데드락이 발생할 수 있다.
    
    ### **Deadlock Case 2**
    
    트랜잭션 A, B, C를 가정하고 아래 INSERT 상황과 DELETE 상황에서 어떻게 내부적으로 동작하는지 살펴보자.
    
    ### **INSERT 경쟁 상황**
    
    - A, B, C 순서로 같은 key값을 가지는 데이터를 INSERT 하기 위해 경쟁
        - A 에서 `INSERT INTO table (pk) VALUES (3);` 실행하면 A에서 exclusive lock 획득
        - B와 C에서도 동일한 INSERT 구문 실행한다. (B, C는 대기상태로 빠짐)
        - A를 rollback하는 순간 B, C가 경쟁 시작.
            - INSERT의 경우 exclusive lock을 획득 시도해야하지만, 해당 INSERT에서 duplicated key error가 발생하는 경우에는 해당 인덱스 레코드에 대해 일단 shared lock을 먼저 획득 시도하는 특성이 있다.
            - B, C가 동일 인덱스 레코드에 대해 shared lock을 먼저 획득한 후 exclusive lock을 잡으려고 하기 때문에 데드락이 발생. (B가 exclusive lock을 획득하려 해도 C가 획득한 shared lock에 의해 불가능, C -> B의 경우에도 vice versa)
            - 늦게 실행된 C가 deadlock처리되어 트랜잭션이 롤백되어 종료되면, B가 exclusive lock을 획득하여 실행된다.
        - A를 commit하면 B, C는 바로 duplicated key error가 발생하지만 여전히 트랜잭션은 열려있다.
    
    결국 이런 INSERT 상황에서 선행 트랜잭션이 rollback하게되면 나머지 트랜잭션들 중 하나만 성공하고 나머지는 모두 데드락으로 강제 롤백 된다는 것을 알 수 있다. 이 케이스는 얼핏 봐서는 데드락이 발생하지 않을 것 같은 상황처럼 보이기 때문에 문제 발견이 쉽지 않으므로 기억해두는 것이 좋다.
    
    ### **DELETE 경쟁 상황**
    
    INSERT의 경우가 매우 특이한 경우라는 것을 강조하기위해서 DELETE에 대해서는 특이하지 않게 잘 동작하는 것을 확인해보자.
    
    - A, B, C 순서로 같은 key값에 대한 DELETE로 경쟁시키는 경우
        - A가 exclusive lock 획득
        - B가 exclusive lock 획득시도(대기), C가 exclusive lock 획득시도(대기)
        - A가 commit 하는 경우
            - lock의 대상이었던 row가 사라짐
            - 때문에 B, C 모두 대기상태가 종료되면서 affected row=0 결과 리턴함 (B, C 트랜잭션은 계속 열려있음)
        - A가 rollback 하는 경우
            - B가 exclusive lock 획득 C는 계속 대기
    
    ### **INSERT, DELETE 상황 비교 분석**
    
    - INSERT의 경우 duplicated key error 가 발생시 shared lock을 획득 시도하기 때문에 하나 이상의 트랜잭션이 동시에 동일한 row에 대한 shared lock을 획득하게 된다. (shared lock은 여러명이 동시에 획득 가능하기 때문) 트랜잭션 A가 종료되면, 다시 트랜잭션 B가 exclusive lock을 획득 시도하려 하지만 트랜잭션C가 잡고있는 shared lock 때문에 exclusive lock을 획득하는것이 불가능하다. 반대의 경우도 마찬가지이므로 데드락 상황이다.
    - DELETE의 경우 exclusive lock을 획득 시도하기 때문에 한번에 하나의 트랜잭션만 lock을 획득가능하고 나머지는 대기한다. 따라서 데드락 상황이 생기지 않는다.
    
    [https://mangkyu.tistory.com/30](https://mangkyu.tistory.com/30)
    
    [https://velog.io/@rnjsrntkd95/Mysql의-잠금Lock과-데드락DeadLock-발생](https://velog.io/@rnjsrntkd95/Mysql%EC%9D%98-%EC%9E%A0%EA%B8%88Lock%EA%B3%BC-%EB%8D%B0%EB%93%9C%EB%9D%BDDeadLock-%EB%B0%9C%EC%83%9D)
    
    [https://steemit.com/kr/@yjiq150/mysql-innodb-lock-and-deadlock](https://steemit.com/kr/@yjiq150/mysql-innodb-lock-and-deadlock)
    
- 샤딩 방식은 무엇인가요? 만약 본인이 DB를 분산해서 관리해야 한다면, 레플리케이션 방식과 샤딩 방식 중 어떤 것을 사용할 것 같나요?
    
    샤딩
    
    - 같은 테이블 스키마를 가진 데이터를 다수의 데이터베이스에 분산하여 저장하는 방법
        
        = Horizontal Partitioning
        
    - DB 트래픽을 분산할 목적
        - 데이터가 급격히 증가하게 되거나 트래픽이 특정 DB로 몰리는 상황을 대비해서 빠르고 유연하고 안전하게 DB를 증설할 수 있게 한다.(DB 서버의 부하를 분산)
        - Scale-up에는 한계가 있고, Scale-out은 동기화라는 제약이 따르게 되므로 DB 서버의 샤딩은 대규모 시스템 설계와 확장성 확보에 필수 불가결인 요소가 된다.
    - 다수의 복제본으로 구성하고 각 샤드에 어떤 데이터가 저장될 지를 Shard Key를 기준으로 분리한다.
    - Shard Key를 어떻게 정의하느냐에 따라 데이터를 효율적으로 분산시키는 것이 결정됨
    
    샤딩 방법
    
    1. Hash Sharding: 데이터를 어디에 넣을지 해싱하여 결정
    2. Dynamic Sharding: Locator Service를 통해 동적 샤딩 키를 얻어 사용
    3. Entity Group: 관련된 데이터를 하나의 샤드로 사용하는 방식
    
    샤딩 적용시 문제점 및 고려사항
    
    1. 데이터 재분배(Rebalancing Data)
        - 샤딩된 DB의 물리적 한계나 성능 한계 도달시 scale-up작업이 필요한데, 이때 서비스 정지 없이 scale-up할 수 있도록 설계 방향을 잡아야 한다.
    2. 데이터 조인하기
        - 샤딩 DB간 조인이 불가능하므로 데이터 중복에 대한 trade-off
    3. Global Unique key
        - 라우팅을 위해 구분할 수 있는 유일한 키 값이 있어야 한다.
    4. DBMS에서 제공하는 AUTO_INCREMENT를 사용하면 key가 중복될 수 있기 때문에 애플리케이션 레벨에서 key생성을 담당해야 한다.
    5. 프로그래밍 복잡도가 증가하고 데이터가 한쪽 샤드로 몰리면 샤딩이 무의미해짐
    6. 한번 샤딩을 사용하면 샤딩이전의 구조로 돌아가기 힘들다.
    
    레플리케이션 VS 샤딩
    
    ### **레플리케이션(Replication):**
    
    **공통점:**
    
    1. **고가용성 보장:** 주 서버에 장애가 발생해도 보조 서버가 있기 때문에 서비스 중단을 최소화할 수 있다.
    2. **읽기 성능 향상:** 복제된 보조 서버를 통해 읽기 작업을 분산하여 처리할 수 있다.
    
    **차이점:**
    
    1. **데이터 복제 방식:** 레플리케이션은 주 서버의 데이터 변경 사항을 보조 서버로 동기적이거나 비동기적으로 복제해야 한다.
    2. **데이터 일관성:** 동기적 레플리케이션은 데이터 일관성을 보장하나, 비동기적 레플리케이션은 일관성을 희생하고 읽기 성능을 향상시킨다.
    
    ### **샤딩(Sharding):**
    
    **공통점:**
    
    1. **확장성:** 데이터를 여러 노드에 분산하여 처리함으로써 시스템의 확장성을 높인다.
    2. **부하 분산:** 데이터를 분할하여 여러 노드에 분산시킴으로써 부하를 분산시킨다.
    
    **차이점:**
    
    1. **데이터 분할 기준:** 샤딩은 주로 특정 기준에 따라 데이터를 분할하여 여러 노드에 분산시킨다.
    2. **데이터 일관성:** 샤딩은 보통 데이터 일관성을 유지하기 위해 추가적인 노력이 필요하다. 각 샤드 간의 데이터 일관성을 관리하는 것이 중요하다.
    
    1. **레플리케이션은** 일관성이 필요하고, 읽기 작업이 많은 경우 레플리케이션을 선택할 수 있다. 예를 들어, 실시간 분석 및 보고 시스템에서 레플리케이션이 유용할 수 있다.
    2. **샤딩은** 데이터 크기가 매우 크고, 쓰기 작업이 많은 경우 샤딩을 선택할 수 있습니다. 예를 들어, 대규모 웹 응용 프로그램에서 샤딩이 필요할 수 있습니다.

---

- 정규화가 무엇인가요?
    
    정규화란 이상현상이 발생하는 릴레이션을 분해하여 이상현상을 없애는 과정을 말한다. 이상현상이 있는 릴레이션은 이상현상을 일으키는 함수 종속성의 유형에 따라 등급을 구분가능하다. 릴레이션은 정규형 개념으로 구분하며 정규형이 높을 수록 이상현상이 줄어든다.
    
    [https://mangkyu.tistory.com/28](https://mangkyu.tistory.com/28)
    
- 정규화를 하지 않을 경우, 발생할 수 있는 이상현상에 대해 설명해 주세요.
    
    삭제 이상: 튜플 삭제 시 같이 저장된 다른 정보까지 연쇄적으로 삭제되는 현상
    
    삽입 이상: 튜플 삽입 시 특정 속성에 해당하는 값이 없어 NULL을 입력해야 하는 현상
    
    수정 이상: 튜플 수정 시 중복된 데이터의 일부만 수정되어 일어나는 데이터 불일치 현상
    
    삭제 이상(Deletion Anomly)란 튜플을 삭제할 때 저장되어있는 다른 정보도 삭제되어 연쇄 삭제(Triggered Deletion)의 문제가 발생하는 경우를 의미합니다. 
    
    [https://t1.daumcdn.net/cfile/tistory/99903E335A28F31E0F](https://t1.daumcdn.net/cfile/tistory/99903E335A28F31E0F)
    
    위의 그림에서 장미란이라는 학생의 정보를 지울 경우 강의실 103도 같이 사라지게 되어 다른 튜플들이 강의실 103을 사용하지 못하는 경우에 발생한다. 
    
    삽입 이상(Insertion Anomly)란 튜플을 삽입하는 경우에 해당하는 정보가 없어 NULL을 넣는 현상입니다. 
    
    수정 이상(Update Anomly)란 어떤 값을 참조하는 튜플의 값을 수정할 때 같은 데이터를 참조하는 다른 튜플과 데이터가 달라지는 현상입니다. 
    
    예를 들어 위의 테이블에서 박지성이라는 학생과 김연아라는 학생이 같은 데이터베이스라는 수업을 강의실 110호 에서 수강하고 있습니다. 그런데 두 강의는 독립적으로 입력된 데이터이기 때문에 박지성 학생에서 강의실을 201호로 변경하여도 김연아 학생은 110호로 데이터가 그대로 유지되고, 같은 데이터베이스 수업임에도 불구하고 강의실이 달라지는 현상이 발생합니다.
    
    [https://t1.daumcdn.net/cfile/tistory/9982D6335A28F38319](https://t1.daumcdn.net/cfile/tistory/9982D6335A28F38319)
    
    이러한 이상현상은 서로 공유하는 데이터임에도 불구하고 각자의 튜플에 독립적으로 존재하기 때문에 발생합니다. 그러므로 위와 같이 테이블을 분리하여 그 테이블을 통해 강의 제목이나 강의실을 참고하게끔 한다면 이상현상들을 해결할 수 있습니다.
    
    [https://mangkyu.tistory.com/28](https://mangkyu.tistory.com/28)
    
- 각 정규화에 대해, 그 정규화가 진행되기 전/후의 테이블의 변화에 대해 설명해 주세요.
    
    ---
    
    제1 정규형은 릴레이션의 모든 속성 값이 원자값을 갖는 경우입니다. 
    
    예를 들어 고객 취미들(이름, 취미들)이라는 릴레이션에 (추신수, (영화, 음악))이라는 열이 있다고 가정하면 이 속성들이 각각 다른 열로 분해된 릴레이션을 제1 정규형이라 합니다.
    
    ![Untitled](%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8%20%E1%84%83%E1%85%A2%E1%84%87%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%2033c69d4c4ac940b39cd413c6600098d5/Untitled%202.png)
    
    ---
    
    제2 정규형은 릴레이션이 제1 정규형을 만족하고, 기본키가 아닌 속성이 기본키에 완전 함수 종속일 때를 의미합니다. 여기서 완전 함수 종속이라는 말은 기본키로 묶인 복합키가 존재할 때 복합키(A,B,C)가 모여서 하나의 다른 값(X)를 결정하고 복합키의 부분집합이 결정자가 되면 안된다는 뜻입니다. 
    
    예를 들어 아래의 그림과 같이 수강강좌 릴레이션이 있고, (학생번호, 강좌이름)의 복합키를 가지고 있다고 가정합시다. 여기서 학생 번호와 강좌 이름(501, 데이터베이스)이 모여서 성적이라는 하나의 값을 결정하지만, 강의실의 경우에는 학생 번호가 없어도 강좌 이름과 강의실(데이터베이스, 공학관 110) 만으로도 강의실을 결정 할 수 있습니다. 그러므로 이러한 관계를 부분 함수 종속이라고 하며 제2 정규형은 완전 함수 종속을 만족시켜야 하므로 강좌이름과 강의실을 분리하면 제2 정규형이 만들어 집니다.
    
    ![Untitled](%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8%20%E1%84%83%E1%85%A2%E1%84%87%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%2033c69d4c4ac940b39cd413c6600098d5/Untitled%203.png)
    
    ![Untitled](%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8%20%E1%84%83%E1%85%A2%E1%84%87%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%2033c69d4c4ac940b39cd413c6600098d5/Untitled%204.png)
    
    예를 들어 위의 그림과 같이 수강강좌 릴레이션이 있고, (학생번호, 강좌이름)의 복합키를 가지고 있다고 가정합시다. 여기서 학생 번호와 강좌 이름(501, 데이터베이스)이 모여서 성적이라는 하나의 값을 결정하지만, 강의실의 경우에는 학생 번호가 없어도 강좌 이름과 강의실(데이터베이스, 공학관 110) 만으로도 강의실을 결정 할 수 있습니다. 그러므로 이러한 관계를 부분 함수 종속이라고 하며 제2 정규형은 완전 함수 종속을 만족시켜야 하므로 강좌이름과 강의실을 분리하면 제2 정규형이 만들어 집니다.
    
    ---
    
    제3 정규형은 릴레이션 R이 제2 정규형을 만족하고 기본키가 아닌 속성이 기본키에 비이행적(Non-Transitive)으로 종속할 때(직접 종속)를 의미합니다. 여기서 이행적 종속이란, A->B, B->C가 성립할 때 A->C가 성립되는 함수 종속성을 의미합니다. 
    
    ![Untitled](%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8%20%E1%84%83%E1%85%A2%E1%84%87%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%2033c69d4c4ac940b39cd413c6600098d5/Untitled%205.png)
    
    위와 같은 계절학기 릴레이션에서 학생번호 501의 강좌이름이 스포츠경영학으로 변경되면 수강료도 15000원으로 변경되어야 합니다. 그러므로 아래의 속성들을 독립적으로 만드는 것이 아니라 학생 번호로 학생이 수강하는 강좌이름을 찾게 하고 그 학생번호가 참조하는 강좌이름을 참조하여 수강료를 찾게하여 학생번호가 수강료를 참조할 수 있게 끔 만들면 제3 정규형이 됩니다.
    
    ---
    
    BCNF 정규형은 릴레이션 R에서 함수 종속성 X->Y가 성립할 때 모든 결정자 X가 후보키인 정규형입니다. 
    
    ![Untitled](%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8%20%E1%84%83%E1%85%A2%E1%84%87%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%2033c69d4c4ac940b39cd413c6600098d5/Untitled%206.png)
    
    ![Untitled](%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8%20%E1%84%83%E1%85%A2%E1%84%87%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%2033c69d4c4ac940b39cd413c6600098d5/Untitled%207.png)
    
    위의 첫 번째 그림에서 기본키는(학생번호, 특강이름) 이고 교수는 (학생번호, 특강이름)에 완전하게 함수적으로 종속하고 있습니다. 또한 교수 역시도 특강 이름을 결정하며 결정자의 역할을 하고 있습니다. 다음으로 모든 결정자 X가 후보키인지를 확인해야 합니다. (학생번호, 특강이름)은 기본키이므로 당연히 결정자이며 후보키입니다. 하지만 교수는 결정자이면서 후보키가 아니므로 위의 두번째 테이블은 BCNF정규형이 아닙니다. BCNF정규형을 만족하기 위해서 위의 두 번째 테이블을 세번째와 같이 분리해야 합니다.
    
    [https://mangkyu.tistory.com/28](https://mangkyu.tistory.com/28)
    
- 정규화가 무조건 좋은가요? 그렇지 않다면, 어떤 상황에서 역정규화를 하는게 좋은지 설명해 주세요.
    
    
    - 정규화를 통해 만든 테이블을 성능, 개발 편의성 등을 위해 조작하거나 구조를 바꾸는 것.
    - 정규화를 하게 되면 **쓰기**가 **편리**해지는 대신, **읽기**의 성능을 **희생**하게 된다.
        - 테이블을 나누면 **join**을 해야 하는데, join에 드는 비용이 크기 때문.
    - 즉, 읽기가 자주 일어나는 테이블은 정규화로 인해 성능이 저하되는 경우가 있다. 이때 성능 향상을 위해 가장 마지막 수단으로 시도해볼 수 있는 것이 **역정규화를 통한 구조 변경**이다.
    - 그러나, 역정규화를 하기 전 반드시 정규화를 수행해야 한다. 아예 정규화를 수행하지 않은 테이블은 좋은 형태가 아니며, 정규화가 성능을 저하시킨다고 일반화할 수는 없기 때문이다.
    
    ### **정규화의 장단점 :**
    
    **장점:**
    
    1. **데이터 일관성 유지:** 정규화된 데이터베이스는 중복된 데이터가 없으므로 데이터의 일관성을 유지하기 쉽다.
    2. **데이터 중복 최소화:** 데이터의 중복을 최소화하여 저장 공간을 절약하고 데이터 수정 시 발생할 수 있는 이상 현상을 방지한다.
    
    **단점:**
    
    1. **조인 비용 증가:** 정규화된 데이터베이스는 여러 테이블에 데이터가 분산되어 있으므로 데이터를 조회할 때 조인 연산이 많이 필요할 수 있어 성능이 저하될 수 있다.
    2. **복잡성 증가:** 데이터가 분산되어 있기 때문에 데이터베이스 구조가 복잡해질 수 있다.
    3. **읽기 성능 저하:** 많은 조인 연산이 필요하므로 대량의 데이터를 읽을 때 성능이 저하될 수 있다.
    
    ### 역정규화의 장단점 :
    
    장점
    
    - 읽기에 들어가는 부하나 비용을 줄여 성능을 높일 수 있다.
    
    단점
    
    - 역정규화를 할 경우 반드시 시스템의 복잡도가 훨씬 높아지고, 이는 프로그램이 고장날 가능성일 높이는 요인임을 알아야 한다.
    - 정규화하기 전의 문제를 고스란히 갖게 되기 때문이다
        
        (데이터 중복, 역정규화하기 이전의 테이블들이 그대로 남아있음 등)
        
    
    ### **역정규화의 사용 사례:**
    
    1. **성능 향상을 위한 역정규화:** 읽기 성능을 향상시키기 위해 데이터를 중복 저장하거나 테이블을 합치는 등의 역정규화를 수행
    2. **쿼리의 단순화:** 많은 조인이 필요한 쿼리를 단순화하기 위해 역정규화를 사용
    3. **레포팅 및 분석 용도:** 대량의 데이터를 빠르게 조회해야 하는 레포팅이나 분석 용도의 시스템에서 역정규화를 사용하여 성능을 향상시킴
    
    따라서, 역정규화는 성능 향상이나 복잡한 쿼리를 간소화해야 하는 상황에서 유용하게 활용된다. 하지만, 역정규화를 사용할 때는 데이터의 일관성을 유지하기 위해 신중하게 고려해야 한다.
    
    [https://velog.io/@clock509/역정규화](https://velog.io/@clock509/%EC%97%AD%EC%A0%95%EA%B7%9C%ED%99%94)
    

---

- View가 무엇이고, 언제 사용할 수 있나요?
    
    
    데이터베이스에서의 View는 테이블이나 다른 뷰로부터 유도된 가상의 테이블이다. 즉, 기존 테이블이나 다른 뷰로부터 데이터를 가져와 새로운 형태의 테이블을 만들어주는 개념이다. 이는 데이터베이스에서 데이터를 쉽게 검색, 필터링 및 조작할 수 있도록 도와준다. 뷰는 조인문 사용 최소화로 사용상 편의성을 최대화 한다.
    
    일반적으로 데이터베이스에서 View는 다음과 같은 경우에 사용됩니다:
    
    1. 데이터의 보안: View를 사용하여 특정 사용자에게만 허용되는 데이터를 제한하거나 필터링할 수 있다. 예를 들어, 관리자용 View와 일반 사용자용 View를 구성하여 관리자만이 특정 데이터에 접근할 수 있도록 할 수 있다.
    2. 데이터의 간소화: View를 사용하여 복잡한 쿼리를 단순화하고 특정 응용 프로그램 또는 사용 사례에 필요한 데이터만을 포함하는 새로운 데이터베이스 "뷰"를 생성할 수 있다.
    3. 데이터의 조인: 여러 테이블을 조인하여 하나의 가상 테이블을 생성할 수 있다. 이를 통해 데이터베이스에 저장된 정보를 더 편리하게 검색할 수 있다.
    4. 데이터의 요약: View를 사용하여 데이터의 요약 정보를 만들어줄 수 있다. 이를 통해 보고서 생성 및 분석 작업이 용이해진다.
    
    ### **뷰(View)의 특징**
    
    **1.** 뷰는 기본테이블로부터 유도된 테이블이기 때문에 기본 테이블과 같은 형태의 구조를 사용하며, 조작도 기본 테이블과 거의 같다.
    
    **2.** 뷰는 가상 테이블이기 때문에 물리적으로 구현되어 있지 않다.
    
    **3.** 데이터의 논리적 독립성을 제공할 수 있다.
    
    **4.** 필요한 데이터만 뷰로 정의해서 처리할 수 있기 때문에 관리가 용이하고 명령문이 간단해진다.
    
    **5.** 뷰를 통해서만 데이터에 접근하게 하면 뷰에 나타나지 않는 데이터를 안전하게 보호하는 효율적인 기법으로 사용할 수 있다.
    
    **6.** 기본 테이블의 기본키를 포함한 속성(열) 집합으로 뷰를 구성해야지만 삽입, 삭제, 갱신, 연산이 가능하다.
    
    **7.** 일단 정의된 뷰는 다른 뷰의 정의에 기초가 될 수 있다.
    
    **8.** 뷰가 정의된 기본 테이블이나 뷰를 삭제하면 그 테이블이나 뷰를 기초로 정의된 다른 뷰도 자동으로 삭제된다.
    
    ## **뷰(View)사용시 장 단점**
    
    **장점**
    
    **1.** 논리적 데이터 독립성을 제공한다.
    
    **2.** 동일 데이터에 대해 동시에 여러사용자의 상이한 응용이나 요구를 지원해 준다.
    
    **3.** 사용자의 데이터관리를 간단하게 해준다.
    
    **4.** 접근 제어를 통한 자동 보안이 제공된다.
    
    **단점**
    
    **1.** 독립적인 인덱스를 가질 수 없다.
    
    **2.** ALTER VIEW문을 사용할 수 없다. 즉 뷰의 정의를 변경할 수 없다.
    
    **3.** 뷰로 구성된 내용에 대한 삽입, 삭제, 갱신, 연산에 제약이 따른다
    
    데이터베이스 View는 데이터베이스 시스템에서 유연성을 제공하고 복잡한 데이터를 다루는 데 도움이 된다. 일반적으로 View는 데이터를 읽는 데 사용되며 데이터 수정이나 삭제는 원본 테이블에 직접 적용해야 합니다.
    
    [https://coding-factory.tistory.com/224](https://coding-factory.tistory.com/224)
    
- 그렇다면, View의 값을 수정해도 실제 테이블에는 반영되지 않나요?
    
    일반적으로 데이터베이스에서의 View는 가상의 테이블이므로 View를 통해 데이터를 수정하더라도 실제 테이블에는 반영되지 않는다. View는 주로 데이터를 조회하는 용도로 사용되며, 데이터의 수정, 추가 또는 삭제는 View에 반영되지 않고 원본 테이블에 직접 적용해야 한다.
    
    따라서 View를 통해 데이터를 수정하려는 경우에는 직접 해당 테이블을 수정해야 한다. View를 수정하는 것은 가능하지만, 이러한 변경은 View의 정의를 수정하는 것으로 View가 다시 생성되어야 하며, 이는 실제 데이터를 변경하는 것이 아니다.
    
    그러나 일부 데이터베이스 시스템에서는 updatable views(업데이트 가능한 뷰)를 지원하기도 한다. 이 경우 특정 조건을 만족하는 View에 대한 업데이트가 가능하다. 하지만 이는 모든 데이터베이스 시스템에서 지원되는 것은 아니며, 주의해서 사용해야 한다.
    

---

- Schema가 무엇인가요?
    
    스키마(Schema)는 데이터베이스에서 데이터 구조와 관련된 개념을 의미한다. 
    
    (DB의 구조와 제약 조건에 관한 전반적인 명세를 정의한 메타데이터의 집합)
    
    데이터베이스 스키마는 데이터베이스에 저장되는 데이터의 구조, 형식, 관계 등을 정의하는 방법을 제공한다.
    
    일반적으로 스키마는 다음과 같은 내용을 포함할 수 있다.
    
    개체의 특성을 나타내는 **`속성(Attribute)`**, 속성들의 집합으로 이루어진 **`개체(Entity)`**, 개체 사이에 존재하는 **`관계(Relation)`**에 대한 정의, 이들이 유지해야 할 **`제약 조건`**
    
    1. **테이블**: 데이터의 구조를 정의하는 데 사용되는 테이블의 이름과 각 열(필드)의 이름, 데이터 유형, 제약 조건 등을 정의.
    2. **인덱스**: 데이터에 대한 검색을 빠르게 하기 위해 특정 열이나 열의 조합에 대한 인덱스를 정의.
    3. **제약 조건**: 데이터의 무결성을 유지하기 위해 테이블에 적용되는 제약 조건(예: primary key, foreign key, unique key, check constraints 등)을 정의.
    4. **뷰(View)**: 특정 데이터의 조합 또는 데이터의 일부분을 보여주는 가상 테이블을 정의.
    5. **프로시저(Stored Procedure)**: 데이터베이스에서 실행할 수 있는 일련의 작업을 정의.
- Schema의 3계층에 대해 설명해 주세요.
    
    데이터베이스 설계에서 스키마는 일반적으로 세 가지 계층으로 구성됩니다. 
    
    이러한 계층은 개념 스키마, 내부 스키마, 외부 스키마로 구성됩니다.
    
    ![Untitled](%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8%20%E1%84%83%E1%85%A2%E1%84%87%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%2033c69d4c4ac940b39cd413c6600098d5/Untitled%208.png)
    
    1. **외부 스키마(External Schema) = 사용자 뷰(View)**
        - 개별 사용자들의 입장에서 데이터 베이스의 논리적 구조를 정의한 것이다.
        - 동일한 데이터에 대해, 서로 다른 관점을 정의할 수 있도록 허용한다.
        - 하나의 데이터베이스 시스템에는 여러개의 외부 스키마가 존재 가능하며, 하나의 외부 스키마를 여러개의 응용 프로그램이나 사용자가 공용할 수도 있다.
        
    2. **개념적 스키마(Conceptual Schema) = 전체적인 뷰(View)**
        - 개념적 스키마는 데이터베이스의 전체 조직에 대한 논리적인 구조로 물리적인 구현은 고려하지 않음
        - 각 데이터베이스에는 한 개의 개념 스키마만 존재한다.
        - 데이터베이스에서 사용되는 모든 엔터티(개체)와 그들 간의 관계(개체 간의 관계 및 무결성 제약 조건)을 정의한다.
        - 데이터베이스 파일에 저장되는 데이터의 형태를 나타낸다.
        
    3. **내부 스키마(Internal Schema) = 저장 스키마(Storage Schema)**
        - 물리적 저장장치의 입장에서 본 데이터베이스의 구조이다.
        - 개념 스키마를 디스크 기억장치에 물리적으로 구현하기 위한 방법을 기술한 것이다.
        - 저장될 데이터 항목의 내부 레코드 형식, 물리적 순서 등을 나타낸다.
    
    ## **데이터 독립성**
    
    ---
    
    데이터베이스 내의 데이터, 데이터를 사용하는 사용자 및 응용 프로그램, 데이터베이스의 저장 구조가 서로 영향을 받지 않는 성질을 의미한다.
    
    ### **논리적 독립성**
    
    - 개념 스키마가 변경되어도, 에 영향을 주지 않는다.
        
        외부 스키마
        
    
    ### **물리적 독립성**
    
    - 내부 스키마가 변경되어도,  / 에 영향을 주지 않는다.
        
        개념 스키마
        
        외부 스키마
        
    
    예를 들어, 저장 구조 등이 물리적으로 변경되어도 다른 스키마와 독립적인 것을 의미한다.
    
    이러한 세 가지 스키마 계층은 데이터베이스 설계 과정에서 데이터베이스의 구조와 구성 요소를 추상화하고 정의함으로써 데이터베이스를 효과적으로 관리하고 유지보수하는 데 도움이 된다.
    
    [https://iingang.github.io/posts/DB-schema/#google_vignette](https://iingang.github.io/posts/DB-schema/#google_vignette)
    

---

- 질문
    1. 테이블에서 여러 후보키가 있을 때, 각 후보키마다 선택된 기본키가 다를 수 있나요? 그렇다면 어떤 후보키가 기본키로 선택되는지 결정하는 기준은 무엇인가요?
        - 답변
            
            주로 기본키로 선택되는 키는 각 튜플을 식별할 수 있는 유일성과 불변성을 가지는 키이다. 예를 들어, 주민등록번호나 고유 아이디 같은 것이 기본키로 선택될 수 있다. 이는 비즈니스의 요구사항에 따라 달라질 수 있으므로 유일성과 불변성을 만족시키고 향후 변경가능성이 적은 속성을 기본키로 선택해야 한다.
            
            기본키로 선택되는 후보키를 결정하는 기준
            
            1. **유일성(Uniqueness):** 기본키는 각 행을 식별하기 위해 유일해야 한다. 즉, 같은 기본키 값을 가진 두 개의 행이 존재해서는 안된다.
            2. **불변성(Immutability):** 기본키 값은 변경되어서는 안된다. 행의 식별을 위해 사용되는 값이 변경된다면 데이터의 일관성이 깨질 수 있다.
            3. **의미론적인 측면(Semantic Considerations):** 비즈니스 도메인의 요구사항과 데이터의 특성을 고려하여 기본키를 선택해야 한다. 예를 들어, 주민등록번호나 고유 아이디와 같이 개인을 고유하게 식별할 수 있는 값이 주로 기본키로 선택될 수 있다.
            4. **효율성(Efficiency):** 기본키로 선택된 속성이 자주 사용되는 경우 조회 및 조인 연산에서 성능이 향상될 수 있다. 이러한 효율성 측면도 고려해야 한다.
    2.  복합키(Composite Key)와 단일키(Single Key)의 차이는 무엇이며, 각각의 사용 사례는 어떤 것이 있을까요?
        - 답변
            
            복합키는 여러 개의 속성으로 이뤄진 키를 의미하며, 복수의 속성을 조합하여 튜플을 식별합니다. 반면에 단일키는 하나의 속성으로 이뤄진 키를 의미하며, 해당 속성만으로 튜플을 식별합니다. 복합키는 여러 속성으로 이뤄진 경우에 사용되며, 복합키가 복잡한 쿼리나 조인을 피할 수 있는 경우에 사용됩니다. 단일키는 주로 단순한 식별이 필요한 경우에 사용됩니다.
            
            - **복합키**: 복합키는 주로 복잡한 데이터 구조를 가진 테이블에서 사용된다. 여러 속성이 함께 조합되어야 튜플을 식별해야 하는 경우에 사용된다. 예를 들어, 학생 테이블에서 (학년, 반, 학번)으로 구성된 복합키는 특정 학생을 식별하는 데 사용될 수 있다.
            - **단일키**: 단일키는 주로 간단한 데이터 구조를 가진 테이블에서 사용됩니다. 단일 속성만으로도 튜플을 식별할 수 있는 경우에 사용된다. 예를 들어, 도서 테이블에서 ISBN 번호를 단일키로 사용하여 각 도서를 식별할 수 있다.
    3. NoSQL 데이터베이스의 일관성 모델에는 어떤 것들이 있으며, 각 모델이 보장하는 일관성 수준은 어떻게 되나요?
        - 답변
            
            NoSQL 데이터베이스의 일관성 모델로는 강일한 일관성(Strong Consistency), 연결된 일관성(Causal Consistency), 최종적 일관성(Eventual Consistency) 등이 있습니다. 강일한 일관성은 모든 읽기와 쓰기 작업이 일관성을 보장하는 가장 높은 수준의 일관성을 의미합니다. 반면에 최종적 일관성은 일시적으로 일관성이 깨지더라도 시간이 지나면 일관성이 보장되는 일관성 모델을 의미합니다.
            
            1. **강일한 일관성(Strong Consistency):**
                - 모든 노드에서 동일한 데이터 복사본을 즉시 반환하고, 모든 읽기 및 쓰기 작업이 한 번에 모든 복제본에 반영되어 일관성을 보장한다.
                - 즉, 모든 읽기 연산은 가장 최근의 쓰기 연산 결과를 반환한다.
                - 이 모델은 데이터의 일관성을 최우선시하는 시스템에 적합하며, ACID 트랜잭션의 모든 특성을 보장한다.
            2. **연결된 일관성(Causal Consistency):**
                - 연결된 일관성은 다양한 읽기 경로 사이에서 인과 관계를 유지하면서 일관성을 보장한다.
                - 이 모델은 쓰기 작업이 발생한 순서에 따라 읽기 작업의 결과를 결정한다. 즉, 쓰기 작업 간의 순서를 파악하여 읽기 작업에 반영한다.
                - 네트워크 지연이나 패킷 손실로 인한 일시적인 일관성 상태의 변화를 허용한다.
            3. **최종적 일관성(Eventual Consistency):**
                - 최종적 일관성은 모든 복제본이 동일한 값을 가질 때까지 일시적으로 일관성이 깨질 수 있지만, 시간이 지나면 최종적으로 일관성을 보장한다.
                - 쓰기 작업이 발생하면 모든 복제본에 즉시 반영되지 않고, 시간이 지나면 모든 복제본이 동일한 상태가 되도록 복제된다.
                - 이 모델은 높은 가용성과 응답성을 추구하는 분산 시스템에 적합하며, 네트워크 지연이나 복제본 간의 통신 오류에 대해 유연하게 대응할 수 있다.
            
    4. 샤딩을 구현할 때 고려해야 할 주요 요소는 무엇인가요? 샤딩을 통해 확장성을 어떻게 보장할 수 있나요?
        - 답변
            
            샤딩을 구현할 때 고려해야 할 주요 요소로는 데이터의 분산, 샤드 키의 선택, 데이터의 일관성 등이 있습니다. 샤딩을 통해 데이터베이스는 특정 샤드에 할당된 부하를 분산시키고, 확장성을 향상시킬 수 있습니다.
            
            **1. 데이터의 분산:**
            
            - 샤딩은 데이터를 여러 개의 샤드(데이터베이스 파티션)로 분할하여 저장한다.
            - 데이터를 어떻게 분산할지에 대한 결정은 데이터베이스의 크기, 트래픽 패턴, 쿼리의 분포 등을 고려하여 이루어져야 한다.
            
            **2. 샤드 키의 선택:**
            
            - 샤드 키는 데이터를 분산하는 데 사용되는 기준이다.
            - 샤드 키를 선택할 때는 데이터의 균형된 분산, 쿼리의 성능, 확장성 등을 고려해야 한다. 또한 샤드 키가 변경될 가능성도 고려해야 한다.
            
            **3. 데이터의 일관성:**
            
            - 데이터의 일관성은 샤딩된 환경에서 특히 중요한 문제이다. 분산 시스템에서 일관성을 유지하기 위해서는 적절한 일관성 모델을 선택하고 이를 구현해야 한다.
            - 일관성 모델은 사용하는 데이터베이스 시스템에 따라 다르며, 데이터의 일관성 수준을 선택하는 것은 샤딩 시 고려해야 할 사항 중 하나이다.
    5. 샤딩된 데이터베이스에서의 트랜잭션 처리는 어떻게 이루어지며, 이로 인해 발생하는 동시성 제어 문제는 어떻게 해결되나요?
        - 답변
            
            샤딩된 데이터베이스에서 트랜잭션은 여러 샤드에 걸쳐 발생할 수 있으며, 각 샤드에서의 트랜잭션 처리는 분산 트랜잭션 처리 프로토콜에 따라 이루어집니다. 이로 인해 발생하는 동시성 제어 문제는 분산 락을 사용하여 해결될 수 있습니다. 데이터베이스에서는 여러 샤드에 걸친 트랜잭션의 일관성과 동시성을 보장하기 위해 분산 락을 사용하여 데이터의 일관성을 유지합니다.
            
            1. **트랜잭션 시작**: 클라이언트에서 트랜잭션을 시작하면, 각 샤드에서 해당 트랜잭션에 대한 작업을 수행하기 위한 준비가 이루어집니다.
            2. **분산 트랜잭션 처리**: 트랜잭션에 포함된 작업이 여러 샤드에 걸쳐 있는 경우, 분산 트랜잭션 처리 프로토콜에 따라 각 샤드에서 해당 작업을 수행합니다.
            3. **동시성 제어**: 동시성 제어 문제는 여러 샤드 간에 발생할 수 있는 데이터 접근 충돌을 관리하는 것을 의미합니다. 이를 위해 분산 시스템에서는 일반적으로 분산 락이 사용됩니다.
            
            **동시성 제어 문제 해결을 위한 방법:**
            
            1. **분산 락(Distributed Locking)**: 분산 시스템에서는 여러 샤드 간의 동시성을 관리하기 위해 분산 락을 사용합니다. 각 샤드에서는 데이터에 접근하기 전에 해당 데이터의 락을 얻어야 합니다. 이를 통해 여러 트랜잭션이 동시에 동일한 데이터에 접근하는 것을 방지할 수 있습니다.
            2. **Multi-Version Concurrency Control, MVCC**: 몇몇 NoSQL 데이터베이스는 MVCC를 사용하여 동시성을 제어합니다. 각 트랜잭션은 읽기 작업 시점에 데이터의 스냅샷을 가져와 트랜잭션 동안 해당 스냅샷을 사용합니다. 이를 통해 트랜잭션이 실행되는 동안 데이터 변경이 반영되지 않으므로 일관성을 유지할 수 있습니다.
            3. **분산 데이터베이스 트랜잭션 프레임워크(Distributed Database Transaction Framework)**: 일부 NoSQL 데이터베이스는 분산 데이터베이스 트랜잭션 프레임워크를 제공하여 분산 환경에서의 트랜잭션 처리를 관리합니다. 이러한 프레임워크는 트랜잭션 처리, 동시성 제어, 복구 등을 포함한 다양한 기능을 제공하여 데이터의 일관성과 안정성을 유지합니다.
            
    6. 반정규화의 사용 사례를 제시해주세요. 어떤 경우에 반정규화가 데이터베이스 성능을 향상시키는데 도움이 될까요?
        - 답변 예시
            
            가정: 온라인 이커머스 플랫폼에서 상품과 주문 데이터를 관리하는 데이터베이스가 있다고 가정해보자.
            
            **정규화된 데이터베이스 설계:**
            
            1. **상품 테이블 (Products):**
                - 상품 ID (Primary Key)
                - 상품명
                - 가격
                - 카테고리 ID (외래 키)
            2. **카테고리 테이블 (Categories):**
                - 카테고리 ID (Primary Key)
                - 카테고리명
            3. **주문 테이블 (Orders):**
                - 주문 ID (Primary Key)
                - 고객 ID (외래 키)
                - 주문일
                - 상품 ID (외래 키)
                - 수량
                - 총 가격
            
            **문제점:**
            
            - 매번 주문 정보를 조회할 때마다 상품 정보와 카테고리 정보를 가져오기 위해 조인 연산이 필요하다.
            - 대규모 주문 데이터가 쌓일 경우에는 많은 조인이 필요하므로 성능 문제가 발생할 수 있다.
            
            **역정규화를 통한 개선:**
            
            1. **상품 테이블 (Products):**
                - 상품 ID (Primary Key)
                - 상품명
                - 가격
                - 카테고리 ID (외래 키)
                - 카테고리명 (중복 정보 추가)
            2. **주문 테이블 (Orders):**
                - 주문 ID (Primary Key)
                - 고객 ID (외래 키)
                - 주문일
                - 상품 ID (외래 키)
                - 상품명 (중복 정보 추가)
                - 가격 (상품 가격 복제)
                - 수량
                - 총 가격
            
            **개선된 점:**
            
            - 주문 테이블에 상품명과 가격을 중복하여 저장함으로써, 주문 정보 조회 시에 조인 연산이 필요 없어진다. 이렇게 함으로써 읽기 연산이 빨라지고 성능이 향상된다.
    7. 스키마 변경이 발생할 때 영향을 받는 객체들은 무엇이 있을까요? 스키마 변경 시 필요한 절차는 무엇인가요?
        - 답변
            
            스키마 변경이 발생할 때 영향을 받는 객체로는 뷰, 저장 프로시저, 트리거 등이 있습니다. 스키마 변경 시에는 데이터의 일관성을 유지하기 위해 백업을 수행하고, 변경된 스키마를 적용하기 위해 시스템을 일시적으로 중지하는 등의 절차가 필요합니다.